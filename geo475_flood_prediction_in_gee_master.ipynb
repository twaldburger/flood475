{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Geo475 - Flood prediction in Google Earth Engine\n",
        "Go through the notebook and run the cells. Try to understand the code and the overall approach.  \n",
        "Feel free to update code where you see room for improvement.  \n",
        "\n",
        "There are several tasks in the notebook. Please try to solve them but don't spend too much time on them. The goal is to understand the process and the code - solving all the tasks is secondary.  \n",
        "\n",
        "The notebook without answers to the tasks can be found [here](https://github.com/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee.ipynb).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWQwO95HL-yd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Setup"
      ],
      "metadata": {
        "id": "zOtw_pQpNp1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import geemap\n",
        "import geemap.colormaps as cm\n",
        "import time\n",
        "\n",
        "## set some parameters, please update with your project id\n",
        "PROJECT_ID = '' # your GEE project id\n",
        "SAMPLE_SIZE = 100 # number of training locations per flood event and class\n",
        "SEED = 3414 # for reproducible results\n",
        "\n",
        "## connect to GEE\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except ee.EEException:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project=PROJECT_ID)"
      ],
      "metadata": {
        "id": "munACIb96Vfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data exploration and visualization"
      ],
      "metadata": {
        "id": "gl1rsslKSJ7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## define the datasets from which to derive the input features\n",
        "globalFlood = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\")\n",
        "dem = ee.ImageCollection('COPERNICUS/DEM/GLO30') \\\n",
        "        .select('DEM')\n",
        "landcover = ee.ImageCollection('ESA/WorldCover/v200')\n",
        "hydro = ee.Image('MERIT/Hydro/v1_0_1')\n",
        "prec = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \\\n",
        "         .select('total_precipitation')\n",
        "runoffPotential = ee.Image('projects/sat-io/open-datasets/HiHydroSoilv2_0/Hydrologic_Soil_Group_250m') \\\n",
        "                    .remap([1, 2, 3, 4, 14, 24, 34], [1, 2, 3, 4, 1, 3, 4]) \\\n",
        "                    .select('remapped')"
      ],
      "metadata": {
        "id": "pBHxsikA6Vbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Get an overview on the datasets we use. What data do they provide? Who produced them? What is their spatial and temporal resolution? A good starting point is the [Earth Engine Data Catalog](https://developers.google.com/earth-engine/datasets)."
      ],
      "metadata": {
        "id": "xMhp6-quctsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some things to discuss:\n",
        "- How to find information efficiently?\n",
        "- What are characteristics of the datasets worth mentioning?\n",
        "- What are potential problems when using these datasets to train a model?\n",
        "\n",
        "Datasets:\n",
        "- [Global Flood Database v1 (2000-2018)](https://developers.google.com/earth-engine/datasets/catalog/GLOBAL_FLOOD_DB_MODIS_EVENTS_V1#description): 913 flood events between 2000-2018 at 30m resolution. Provided by [Dartmouth Flood Observatory ](https://floodobservatory.colorado.edu/) and based on MODIS data.\n",
        "- [Copernicus DEM GLO-30: Global 30m Digital Elevation Model](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_DEM_GLO30#description): Global Digital Surface Model at 30m resolution. Provided by [Copernicus/ESA](https://spacedata.copernicus.eu/collections/copernicus-digital-elevation-model) and based on data acquired through the TanDEM-X mission between 2011 and 2015.\n",
        "- [ESA WorldCover 10m v200](https://developers.google.com/earth-engine/datasets/catalog/ESA_WorldCover_v200?hl=en#description): Global landcover map for 2021 with 11 landcover classes at 10m resolution. Provided by [ESA](https://esa-worldcover.org/en).\n",
        "- [MERIT Hydro: Global Hydrography Datasets](https://developers.google.com/earth-engine/datasets/catalog/MERIT_Hydro_v1_0_1#description): Global flood direction map at \\~90m resolution (at equator). The dataset is provided by the [University of Tokyo](http://hydro.iis.u-tokyo.ac.jp/~yamadai/MERIT_Hydro/index.html) and based on various elevation and water body dataset with vintages between 1987 and 2017.\n",
        "- [ERA5-Land Hourly - ECMWF Climate Reanalysis](https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_HOURLY): Global reanalysis dataset containing hourly climate variables at ~11km resolution. Provided by [Copernicus/ESA](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land?tab=overview).\n",
        "- [Soil Grids 250m v2.0](https://gee-community-catalog.org/projects/isric/): Global dataset of soil properties at 250m resolution provided by (ISRIC)[https://www.isric.org/].\n",
        "</font>"
      ],
      "metadata": {
        "id": "hAyKCsRKVOon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## subtract the permanent water bodies from the flooded areas\n",
        "def subtractPermanentWater(img):\n",
        "  flood = img.select('flooded')\n",
        "  perm = img.select('jrc_perm_water')\n",
        "  return flood.multiply(perm.eq(0))\n",
        "flood = globalFlood.map(subtractPermanentWater).sum()\n",
        "\n",
        "## initialize map and add some basemaps\n",
        "# see https://stackoverflow.com/a/33023651 for Google basemap list\n",
        "Map = geemap.Map(center=[27, -81], zoom=7, basemap='CartoDB.DarkMatter')\n",
        "Map.add_basemap('CartoDB.Positron', show=False)\n",
        "Map.add_tile_layer(\"https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}\", name=\"Google.Roadmap\", attribution=\"Google\", shown=False)\n",
        "Map.add_tile_layer(\"https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}\", name=\"Google.Satellite\", attribution=\"Google\", shown=False)\n",
        "\n",
        "## add historic floods\n",
        "flood_vis = {'min':0, 'max':10, 'palette':cm.palettes.Blues}\n",
        "Map.add_layer(flood.selfMask(), flood_vis, 'Historic floods')\n",
        "Map.add_colorbar(flood_vis, label=\"Number of floods\", layer_name=\"Historic floods\")\n",
        "\n",
        "## add elevation\n",
        "elevation_vis = {'min':0, 'max':3000, 'palette':cm.palettes.dem}\n",
        "Map.addLayer(dem.mosaic(), elevation_vis, 'Elevation', shown=False)\n",
        "Map.add_colorbar(elevation_vis, label=\"Elevation [m]\", layer_name=\"Elevation\")\n",
        "\n",
        "## add landcover\n",
        "landcover_vis = {'bands':['Map']}\n",
        "Map.addLayer(landcover.first(), landcover_vis, 'Landcover', shown=False)\n",
        "Map.add_legend(title=\"Landcover\", builtin_legend=\"ESA_WorldCover\", layer_name='Landcover')\n",
        "\n",
        "## add upstream drainage area\n",
        "upa_vis = {'min':0, 'max':10, 'palette':cm.palettes.Purples}\n",
        "Map.addLayer(hydro.select('upa'), upa_vis, 'Upstream drainage area', shown=False)\n",
        "Map.add_colorbar(upa_vis, label=\"Upstream drainage area [km^2]\", layer_name=\"Upstream drainage area\")\n",
        "\n",
        "## add precipitation\n",
        "prec_vis = {'min':0, 'max':5, 'palette':cm.palettes.turbo}\n",
        "Map.addLayer(prec.filter(ee.Filter.date('2024-10-01', '2024-10-31')).sum(), prec_vis, 'Precipitation', shown=False)\n",
        "Map.add_colorbar(prec_vis, label=\"Precipitation [m]\", layer_name=\"Precipitation\")\n",
        "\n",
        "## add runoff potential\n",
        "ee_class_table = \"\"\"\n",
        "Value\tColor\tDescription\n",
        "1\tedf8e9\tHSG-A: low runoff potential (>90% sand and <10% clay)\n",
        "2\tbae4b3\tHSG-B: moderately low runoff potential (50-90% sand and 10-20% clay)\n",
        "3\t74c476\tHSG-C: moderately high runoff potential (<50% sand and 20-40% clay)\n",
        "4\t238b45\tHSG-D: high runoff potential (<50% sand and >40% clay)\n",
        "\"\"\"\n",
        "runoff_legend = geemap.legend_from_ee(ee_class_table)\n",
        "runoff_vis = {'min':0, 'max':4, 'palette':list(runoff_legend.values())}\n",
        "Map.addLayer(runoffPotential, runoff_vis, 'Runoff potential', shown=False)\n",
        "Map.add_legend(\"Runoff potential\", legend_dict=runoff_legend, layer_name=\"Runoff potential\")\n",
        "\n",
        "## display map\n",
        "Map"
      ],
      "metadata": {
        "id": "TmwnW78Of3Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Add the input datasets to the map so you can explore them visually. We are interested in elevation, landcover, upstream drainage area, precipitation and runoff potential. You can find the geemap documentation [here](https://geemap.org/)."
      ],
      "metadata": {
        "id": "BUj9DEb7fU4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some things to discuss:\n",
        "- Does anyone want to share their map?\n",
        "- How to add layers with legends and colorbars in geemap?\n",
        "- Any new specific findings on data format when visualizing the datasets?\n",
        "- How are the floods distributed? Are there geographies without any or with only a few floods?"
      ],
      "metadata": {
        "id": "OamQZyhAV_py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Training dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "Yv7ybAUMSDmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pointQuery(fc:ee.FeatureCollection, img:ee.Image, prop:str) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Returns pixel values at locations using a feature collection and an image.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  fc: : ee.FeatureCollection\n",
        "    Collection of points at which to query the image.\n",
        "  img : ee.Image\n",
        "    The image to query.\n",
        "  prop : str\n",
        "    Name of new property to hold the query results.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Input FeatureCollection with lookup values added as new property.\n",
        "  \"\"\"\n",
        "  fc = img.reduceRegions(collection=fc, reducer=ee.Reducer.first())\n",
        "  return fc.map(lambda feat: feat.set(prop, feat.get('first')))\n",
        "\n",
        "\n",
        "def removeProperty(fc:ee.FeatureCollection, prop:str) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Removes a property by name from a feature collection.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  fc : ee.FeatureCollection\n",
        "    Collection from which to remove the property.\n",
        "  prop : str\n",
        "    Property to remove.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Input collection without the removed property.\n",
        "  \"\"\"\n",
        "  selectProperties = fc.propertyNames().filter(ee.Filter.neq('item', prop))\n",
        "  return fc.select(selectProperties)\n",
        "\n",
        "\n",
        "def createSample(img:ee.Image) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Samples training dataset for a single flood image.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  img : ee.Image\n",
        "    Input image.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Sampled and enriched training data.\n",
        "  \"\"\"\n",
        "\n",
        "  ## subtract permanent water bodies from flooded areas\n",
        "  permanent = img.select('jrc_perm_water')\n",
        "  water = img.select('flooded')\n",
        "  flooded = water.subtract(permanent).gt(0)\n",
        "\n",
        "  ## get the total and maximum precipitation over 14 days prior to the event end date\n",
        "  end = img.getNumber('system:time_end')\n",
        "  start = end.subtract(1209600000) # timestamp in milliseconds: 60 * 60 * 24 * 14 * 1000\n",
        "  precSum = prec.filter(ee.Filter.date(start, end)).sum()\n",
        "  precMax = prec.filter(ee.Filter.date(start, end)).max()\n",
        "\n",
        "  ## sample equal number of flooded and non-flooded points\n",
        "  sample = flooded.stratifiedSample(numPoints=SAMPLE_SIZE, classBand='flooded', geometries=True)\n",
        "\n",
        "  ## add image id in case we want to join the event metadata later\n",
        "  sample = sample.map(lambda x: x.set('eventId', img.get('system:index')))\n",
        "\n",
        "  ## enrich sample by running point lookups on multiple datasets\n",
        "  sample = pointQuery(sample, dem.mosaic(), 'demElevationAbs')\n",
        "  sample = pointQuery(sample, ee.Terrain.aspect(dem.mosaic()), 'demAspect')\n",
        "  sample = pointQuery(sample, ee.Terrain.slope(dem.mosaic()), 'demSlope')\n",
        "  sample = pointQuery(sample, landcover.first(), 'landcover')\n",
        "  sample = pointQuery(sample, hydro.select('upa'), 'upa')\n",
        "  sample = pointQuery(sample, runoffPotential, 'runoffPot')\n",
        "  sample = pointQuery(sample, precSum, 'precSum')\n",
        "  sample = pointQuery(sample, precMax, 'precMax')\n",
        "\n",
        "  ## remove first-property\n",
        "  sample = sample.map(lambda feat: removeProperty(feat, 'first'))\n",
        "\n",
        "  ## normalize elevation\n",
        "  elevationRange = dem.mosaic().reduceRegion(geometry=img.geometry(), reducer=ee.Reducer.minMax())\n",
        "  min = ee.Number(elevationRange.get('DEM_min'))\n",
        "  max = ee.Number(elevationRange.get('DEM_max'))\n",
        "  def normalizeElevation(feat:ee.Feature) -> ee.Feature:\n",
        "    return feat.set('demElevationNorm', (ee.Number(feat.get('demElevationAbs')).subtract(min)).divide(max.subtract(min)))\n",
        "  sample = sample.filter(ee.Filter.notNull(ee.List(['demElevationAbs']))).map(normalizeElevation)\n",
        "\n",
        "  return sample"
      ],
      "metadata": {
        "id": "U7fUtqOy6VTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Try to understand the code in the cell above. Why are we using *ee.Image.stratifiedSample* in line 70 instead of using the much faster *ee.Image.Sample* method? Why are we using the complicated GEE methods in lines 65-76 and 90-94 instead of simply using plain Python? What does *ee.FeatureCollection.map* do? Why do we not just write a simple for-loop instead? Why do we normalize the elevation values?"
      ],
      "metadata": {
        "id": "qL-_naeIdr1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some things to discuss:\n",
        "- Where can we quickly look up documentation on GEE classes and functions?\n",
        "- Check out the documentation section in the [GEE Code editor](https://code.earthengine.google.com/) if not done already.  \n",
        "\n",
        "Answers to questions:\n",
        "- *stratifiedSample* samples the same number of locations within each class. Since our flood footprints mostly contain non-flooded pixels, using *stratifiedSample* is a convenient way to avoid oversampling non-flooded pixels. However, there might also be a risk of *stratifiedSample* oversampling certain flooded areas if the flood footprint is very small.\n",
        "- We want to execute all the code in GEE itself so we can benefit from its optimization and parallelisation. If we would use plain Python, we would need to fetch the info from GEE server into our Colab Runtime which would make the whole process extremely inefficient.\n",
        "- *map* iterates over a feature collection and applies an algorithm to each feature. This process is run in parallel on the GEE server. Using a Python for-loop instead would loose the parallel execution and also create all the problems mentioned in the last question.\n",
        "- We use a global flood dataset, but look at the individual events independently. We do not want to create a bias towards the general elevation of the region where an event took place and are therefore normalizing the elevation within each image (and therefore for each event)."
      ],
      "metadata": {
        "id": "LwevqufMX4YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create task to enrich sample and store the result as an asset\n",
        "properties = ['demAspect', 'demElevationAbs', 'demElevationNorm', 'demSlope', 'eventId', 'flooded', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa', '.geo']\n",
        "sample = globalFlood.map(createSample).flatten()\n",
        "sample = sample.filter(ee.Filter.notNull(properties)).distinct(properties)\n",
        "task = ee.batch.Export.table.toAsset(sample, description='flood475-sampling', assetId=f\"projects/{PROJECT_ID}/assets/flood475_sample\")"
      ],
      "metadata": {
        "id": "W6ErNPvdBZm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## run and monitor the task\n",
        "task.start()\n",
        "while task.active():\n",
        "  ts = task.status()\n",
        "  if ts['start_timestamp_ms']>0:\n",
        "    s = round((ts['update_timestamp_ms']-ts['start_timestamp_ms'])/1000)\n",
        "  else:\n",
        "    s = round((ts['update_timestamp_ms']-ts['creation_timestamp_ms'])/1000)\n",
        "  print(f\"task '{ts['description']}' is {ts['state']} for {s} seconds\")\n",
        "  time.sleep(60)\n",
        "task.status()"
      ],
      "metadata": {
        "id": "s6I0aPqCXBIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** There are multiple places (outside of Google Colab) where we can also monitor our tasks. Can you find them?  \n",
        "\n",
        "> **Task:** Add the sampled data points to your map from above."
      ],
      "metadata": {
        "id": "jvoojztSaYDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 places to check tasks:\n",
        "- [GEE Code editor](https://code.earthengine.google.com/)\n",
        "- [Task Manager](https://code.earthengine.google.com/tasks)\n",
        "- [Tasks Page in the Cloud Console](https://console.cloud.google.com/earth-engine/tasks?project=ee-timwaldburger-flood475)"
      ],
      "metadata": {
        "id": "oBo799RWYo5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## import the training dataset\n",
        "sample = ee.FeatureCollection(f\"projects/{PROJECT_ID}/assets/flood475_sample\")\n",
        "\n",
        "visParams = {\n",
        "    'color': '#FFFFFF',\n",
        "    'colorOpacity': 1,\n",
        "    'pointSize': 5,\n",
        "    'pointShape': 'circle',\n",
        "    'width': 2,\n",
        "    'lineType': 'solid',\n",
        "    'fillColorOpacity': 1,\n",
        "}\n",
        "Map.add_styled_vector(sample, column='flooded', palette=['#ffffbf', '#d7191c'], layer_name='Training data', **visParams)\n",
        "Map"
      ],
      "metadata": {
        "id": "IGikkZOFV98p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Model training"
      ],
      "metadata": {
        "id": "PqUK7JJ68JfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## partition into 70% training and 30% validation samples\n",
        "sample = sample.randomColumn('random', seed=SEED)\n",
        "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
        "validation = sample.filter(ee.Filter.gte('random', 0.7))\n",
        "\n",
        "## train a random forest\n",
        "properties = ['demAspect', 'demElevationNorm', 'demSlope', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa']\n",
        "randomForest = ee.Classifier.smileRandomForest(10).setOutputMode('CLASSIFICATION')\n",
        "classifier = randomForest.train(\n",
        "    features=training,\n",
        "    classProperty='flooded',\n",
        "    inputProperties=properties\n",
        ")"
      ],
      "metadata": {
        "id": "V6XMurxl8NJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on training set\n",
        "trainConfusionMatrix = classifier.confusionMatrix()\n",
        "trainFscores = trainConfusionMatrix.fscore().getInfo()\n",
        "print(f\"train accuracy: {trainConfusionMatrix.accuracy().getInfo()}\")\n",
        "print(f\"train f-score non-flooded: {trainFscores[0]}\")\n",
        "print(f\"train f-score flooded: {trainFscores[1]}\")\n",
        "\n",
        "# accuracy on test set\n",
        "testConfusionMatrix = validation.classify(classifier).errorMatrix('flooded', 'classification')\n",
        "testFscores = testConfusionMatrix.fscore().getInfo()\n",
        "print(f\"test accuracy: {testConfusionMatrix.accuracy().getInfo()}\")\n",
        "print(f\"test f-score non-flooded: {testFscores[0]}\")\n",
        "print(f\"test f-score flooded: {testFscores[1]}\")"
      ],
      "metadata": {
        "id": "UAbN6t2uMXlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** What do accuracy and F1-Score describe? Do you think your model performs well given those results?"
      ],
      "metadata": {
        "id": "5BtaK0kpgM8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some things to discuss:\n",
        "- Does the model perform well based on the accuracy and F-Score?\n",
        "\n",
        "Answers to questions:\n",
        "- Accuracy: How often is the model right? An accuracy of 0.9 is generally considered good in many machine learning contexts. It means that your model makes the correct prediction 90% of the time.\n",
        "- F1-Score: Metric that combines precision and recall into a single value. It provides a balanced measure of a model's performance, considering both the accuracy of positive predictions (precision) and the ability to identify all positive instances (recall). An F1-score of 0.8 is generally considered good. It indicates that your model is performing well in terms of both precision and recall.  \n",
        "- Recall: How many positive predictions can the model identify?\n",
        "- Precision: How often are positive predictions correct?\n"
      ],
      "metadata": {
        "id": "CxPn2Fgqgrz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Prediction"
      ],
      "metadata": {
        "id": "rZAwkZyHCt-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(roi: ee.Geometry, classifier: ee.Classifier) -> ee.Image:\n",
        "  \"\"\"\n",
        "  Predict flood probability for a given region of interest.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  roi : ee.Geometry\n",
        "    Region of interest.\n",
        "  classifier : ee.Classifier\n",
        "    Trained classifier.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.Image\n",
        "    Flood probabilities.\n",
        "  \"\"\"\n",
        "\n",
        "  ## normalize elevation\n",
        "  elevationRange = dem.mosaic().reduceRegion(geometry=roi, reducer=ee.Reducer.minMax(), scale=30, bestEffort=True)\n",
        "  min = ee.Number(elevationRange.get('DEM_min'))\n",
        "  max = ee.Number(elevationRange.get('DEM_max'))\n",
        "\n",
        "  ## calculate start and end data for precipitation data aggregation\n",
        "  end = ee.Date('2024-10-31T00:00:00').millis()\n",
        "  start = end.subtract(1209600000) # timestamp in milliseconds: 60 * 60 * 24 * 14 * 1000\n",
        "\n",
        "  ## create composite of all relevant datasets\n",
        "  composite = ee.Image.cat(\n",
        "      ee.Terrain.aspect(dem.mosaic()),\n",
        "      dem.mosaic().unitScale(min, max),\n",
        "      ee.Terrain.slope(dem.mosaic()),\n",
        "      landcover.first(),\n",
        "      prec.filter(ee.Filter.date(start, end)).max(),\n",
        "      prec.filter(ee.Filter.date(start, end)).sum(),\n",
        "      runoffPotential,\n",
        "      hydro.select('upa')\n",
        "  ).rename(properties)\n",
        "\n",
        "  ## classify the composite\n",
        "  classifier = classifier.setOutputMode('MULTIPROBABILITY')\n",
        "  classified = composite.classify(classifier).clip(roi)\n",
        "  probabilities = classified.arrayFlatten([['non-flooded', 'flooded']])\n",
        "  probability = probabilities.select('flooded')\n",
        "\n",
        "  return probability"
      ],
      "metadata": {
        "id": "yrmCVjlIDQZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Try to understand the code in the cell above. What does the *predict*-function do?"
      ],
      "metadata": {
        "id": "nh_alZwKjkiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer to the question:\n",
        "- The *predict*-function creates a composite image by combining all the datasets we used for model training. It normalizes the elevation and aggregates precipitation. It then classifies every pixel in the composite using the pre-trained model."
      ],
      "metadata": {
        "id": "XInGMxUJjtZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## run prediction for current map bounds\n",
        "probability = predict(roi=ee.Geometry.BBox(*Map.getBounds()), classifier=classifier)\n",
        "\n",
        "## update mask to exclude permanent water\n",
        "permanentWater = globalFlood.select('jrc_perm_water').mosaic()\n",
        "probability = probability.updateMask(permanentWater.neq(1))\n",
        "\n",
        "## update the map\n",
        "probability_vis = {'min':0, 'max':1, 'palette':cm.palettes.cividis}\n",
        "Map.addLayer(probability.selfMask(), probability_vis, 'Flooded probability')\n",
        "Map.add_colorbar(probability_vis, label=\"Flooded probability\", layer_name=\"Flooded probability\", font_size=9)\n",
        "Map"
      ],
      "metadata": {
        "id": "4HgIVRX3f6J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Remove pixels representing permanent water bodies from the prediction.  \n",
        "\n",
        "> **Task:** Check various areas on the map. Where does the model seem to perform well. Where does it perform bad? Can you explain why it performs bad in certain areas? Do you see any bias towards a specific feature?\n",
        "\n",
        "> **Task:** Go back to the cell where we trained the model and play around with hyperparameters. Can you improve the model?  \n",
        "\n",
        "> **Task:** Check in the GEE documentation which other models are available and try to run them. What differences do you see? Which model works best?"
      ],
      "metadata": {
        "id": "qhGDziOU_m2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some things to discuss:\n",
        "- The model seems to assign a high flood probability to mountain ranges and and glaciers. This does not make much sense. A possible explanation is the lack of such areas in the training data."
      ],
      "metadata": {
        "id": "mgJ2oU6Xk3eV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Feedback\n",
        "\n",
        "I try to constantly improve the exercise and would therefore much appreciate if you could take 2 minutes to provide me a short feedback. Thank you!\n",
        "\n",
        "Please run the cell below to display a Google Form where you can provide your feedback. I will not collect your mail address so the feedback is anonymous."
      ],
      "metadata": {
        "id": "Sb2D0kRqrZHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<iframe src=\"https://docs.google.com/forms/d/e/1FAIpQLScg8j6ORkqgWw4QEHpkeOy2PxYKSdgop3PPvaA1_WT54igFIA/viewform?embedded=true\" width=\"640\" height=\"1304\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loadingâ€¦</iframe>"
      ],
      "metadata": {
        "id": "WxH4RUe4rW3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Bonus: run country-scale prediction\n",
        "The code below runs the trained model for all of Switzerland at 30 m resolution and exports the result to GEE. It runs in about 20 minutes. No need to run in the lab, but feel free to try it out and play around with different models, geographies and settings."
      ],
      "metadata": {
        "id": "TebjhRrVgpVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## get country shape\n",
        "countries = ee.FeatureCollection('WM/geoLab/geoBoundaries/600/ADM0')\n",
        "ch = countries.filterMetadata('shapeName', 'equals', 'Switzerland')\n",
        "\n",
        "## run prediction for Switzerland\n",
        "flooded_prob = predict(roi=ch.geometry(), classifier=classifier)\n",
        "\n",
        "## update the map\n",
        "flooded_prob_vis = {'min':0, 'max':1, 'palette':cm.palettes.cividis}\n",
        "Map.addLayer(flooded_prob.selfMask(), flooded_prob_vis, 'Flooded probability')\n",
        "Map.add_colorbar(flooded_prob_vis, label=\"CH flooded probability\", layer_name=\"CH flooded probability\", font_size=9)\n",
        "Map"
      ],
      "metadata": {
        "id": "AXdcJDjWgVrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create export task\n",
        "task = ee.batch.Export.image.toAsset(\n",
        "  flooded_prob,\n",
        "  description='flood475-ch-prediction',\n",
        "  assetId=f\"projects/{PROJECT_ID}/assets/flood475_ch_prediction\",\n",
        "  scale=30,\n",
        "  maxPixels=500_000_000\n",
        ")\n",
        "\n",
        "## run and monitor the task\n",
        "task.start()\n",
        "while task.active():\n",
        "  ts = task.status()\n",
        "  if ts['start_timestamp_ms']>0:\n",
        "    s = round((ts['update_timestamp_ms']-ts['start_timestamp_ms'])/1000)\n",
        "  else:\n",
        "    s = round((ts['update_timestamp_ms']-ts['creation_timestamp_ms'])/1000)\n",
        "  print(f\"task '{ts['description']}' is {ts['state']} for {s} seconds\")\n",
        "  time.sleep(60)\n",
        "task.status()"
      ],
      "metadata": {
        "id": "6rWlXxOGfqQM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}