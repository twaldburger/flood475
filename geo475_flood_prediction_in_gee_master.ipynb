{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee_master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWQwO95HL-yd"
      },
      "source": [
        "# Geo475 - Flood prediction in Google Earth Engine\n",
        "\n",
        "Go through the notebook and run the cells. Try to understand the code and the overall approach.  \n",
        "Feel free to update code where you see room for improvement and do not hesitate to ask questions.\n",
        "\n",
        "There are several tasks in the notebook, which are intended to trigger exploration and discussions. Please try to solve them but do not spend too much time on them. The goal is to understand the process and the code - solving all the tasks is secondary. \n",
        "\n",
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Tasks are marked like this.\n",
        "</div> \n",
        "\n",
        "The notebook without answers to the tasks can be found [here](https://github.com/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtw_pQpNp1J"
      },
      "source": [
        "---\n",
        "## Setup\n",
        "\n",
        "We use the *[Earth Engine](https://developers.google.com/earth-engine/guides/python_install)* and the *[geemap](https://geemap.org/)* Python libraries to interact with GEE. *geemap* was originally created because the offical *ee* library had relatively little documentation and limited functionality while *geemap* enables users to easily analyze and visualize Earth Engine datasets interactively within a Jupyter-based environment.\n",
        "\n",
        "In this first code cell, we are importing our dependencies, setting some global variables and authenticating with GEE. All dependencies are already pre-installed in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "munACIb96Vfd"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import geemap\n",
        "import geemap.colormaps as cm\n",
        "import time\n",
        "\n",
        "## set some parameters, please update with your project id\n",
        "PROJECT_ID = '' # your GEE project id\n",
        "SAMPLE_SIZE = 100 # number of training locations per flood event and class\n",
        "SEED = 3414 # for reproducible results\n",
        "\n",
        "## connect to GEE\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except ee.EEException:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl1rsslKSJ7v"
      },
      "source": [
        "---\n",
        "## Data exploration and visualization\n",
        "\n",
        "GEE is built around two fundamental classes to represent raster and vector data: *[ee.Image](https://developers.google.com/earth-engine/apidocs/ee-image)* represents a single raster image while *[ee.Feature](https://developers.google.com/earth-engine/apidocs/ee-feature)* represents a geometry. Multiple images or geometries are represented as *[ee.ImageCollection](https://developers.google.com/earth-engine/apidocs/ee-imagecollection)* or as *[ee.FeatureCollection](https://developers.google.com/earth-engine/apidocs/ee-featurecollection)*.\n",
        "\n",
        "The main catalogs for GEE data are the official [Earth Engine Data Catalog](https://developers.google.com/earth-engine/datasets) and the community-maintained [awesome-gee-community-catalog](https://gee-community-catalog.org/). The Earth Engine Data Catalog stores over 90 petabytes of data and over 1'000 datasets while the awesome-gee-community-catalog stores about 500 terabytes of data and around 4'000 datasets. One of the big benefits of this data is, that they are curated, meaning that they have already been pre-processed and ingested and are ready for analysis. All we need to do is to select and use them.\n",
        "\n",
        "In the cell below, we select a few input datasets that we will be using to sample our training data for the model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBHxsikA6Vbh"
      },
      "outputs": [],
      "source": [
        "## define the datasets from which to derive the input features\n",
        "globalFlood = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\")\n",
        "dem = ee.ImageCollection('COPERNICUS/DEM/GLO30') \\\n",
        "        .select('DEM')\n",
        "landcover = ee.ImageCollection('ESA/WorldCover/v200')\n",
        "hydro = ee.Image('MERIT/Hydro/v1_0_1')\n",
        "prec = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \\\n",
        "         .select('total_precipitation')\n",
        "runoffPotential = ee.Image('projects/sat-io/open-datasets/HiHydroSoilv2_0/Hydrologic_Soil_Group_250m') \\\n",
        "                    .remap([1, 2, 3, 4, 14, 24, 34], [1, 2, 3, 4, 1, 3, 4]) \\\n",
        "                    .select('remapped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMhp6-quctsy"
      },
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Check out the <a href=\"https://developers.google.com/earth-engine/datasets\" target=\"_blank\">Earth Engine Data Catalog</a> and the <a href=\"https://gee-community-catalog.org/\" target=\"_blank\">awesome-gee-community-catalog</a>.\n",
        "  <ol style=\"margin-top: 10px; margin-bottom: 0;\">\n",
        "    <li>How are they structured?</li>\n",
        "    <li>What information do they provide?</li>\n",
        "    <li>Can you find the datasets we intend to use?</li>\n",
        "    <li>What are the spatial and temporal resolution of \"our\" datasets?</li>\n",
        "  </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAyKCsRKVOon"
      },
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #1fbd5bff;\">\n",
        "    <strong style=\"color: #1fbd5bff;\">Solution:</strong>\n",
        "    <ol>\n",
        "        <li>Google organizes the Earth Engine Data Catalog as a <a href=\"https://stacspec.org/en\">SpatioTemporal Asset\n",
        "                Catalog (STAC)</a> compliant repository. Datasets are grouped by Provider (e.g., NASA, ESA, USGS) and Theme\n",
        "            (e.g., Landsat, Sentinel, Climate, Terrain). Datasets are classified into three types: <em>ee.Image</em>,\n",
        "            <em>ee.ImageCollection</em>, and <em>ee.FeatureCollection</em>.<br>The awesome-gee-community-catalog acts more\n",
        "            like a curated library of links pointing to various Google Cloud projects where researchers have stored their\n",
        "            data. It is organized by Categories and Sub-categories (e.g., Hydrology -&gt; Surface Water).</li>\n",
        "        <li>Both catalogs provide a short description of the dataset, as well as some band/attribute information, license\n",
        "            and citation info, and some code snippets. The Earth Engine Data Catalog is more strict and structured in the\n",
        "            metadata provided.</li>\n",
        "        <li>See table below.</li>\n",
        "        <li>See table below.</li>\n",
        "    </ol>\n",
        "    <br>\n",
        "    <table>\n",
        "        <thead>\n",
        "            <tr>\n",
        "                <th style=\"text-align:left\">Dataset Name</th>\n",
        "                <th style=\"text-align:left\">Content</th>\n",
        "                <th style=\"text-align:left\">Provider</th>\n",
        "                <th style=\"text-align:left\">Spatial resolution</th>\n",
        "                <th style=\"text-align:left\">Temporal coverage</th>\n",
        "                <th style=\"text-align:left\">Spatial coverage</th>\n",
        "            </tr>\n",
        "        </thead>\n",
        "        <tbody>\n",
        "            <tr>\n",
        "                <td style=\"text-align:left\"><a\n",
        "                        href=\"https://developers.google.com/earth-engine/datasets/catalog/GLOBAL_FLOOD_DB_MODIS_EVENTS_V1\">Global\n",
        "                        Flood Database v1</a></td>\n",
        "                <td style=\"text-align:left\">913 selected flood events derived from Terra and Aqua MODIS sensors.</td>\n",
        "                <td style=\"text-align:left\">Dartmouth Flood Observatory</td>\n",
        "                <td style=\"text-align:left\">30m</td>\n",
        "                <td style=\"text-align:left\">2000 – 2018</td>\n",
        "                <td style=\"text-align:left\">global</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"text-align:left\"><a\n",
        "                        href=\"https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_DEM_GLO30\">Copernicus\n",
        "                        DEM GLO-30</a></td>\n",
        "                <td style=\"text-align:left\">Digital Surface Model (DSM) representing the surface of the Earth including\n",
        "                    buildings, infrastructure and vegetation.</td>\n",
        "                <td style=\"text-align:left\">Copernicus/ESA</td>\n",
        "                <td style=\"text-align:left\">30m</td>\n",
        "                <td style=\"text-align:left\">2011 – 2015</td>\n",
        "                <td style=\"text-align:left\">global</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"text-align:left\"><a\n",
        "                        href=\"https://developers.google.com/earth-engine/datasets/catalog/ESA_WorldCover_v200\">ESA\n",
        "                        WorldCover 10m v200</a></td>\n",
        "                <td style=\"text-align:left\">Land cover map with 11 classes based on Sentinel-1 and Sentinel-2 data.</td>\n",
        "                <td style=\"text-align:left\">ESA</td>\n",
        "                <td style=\"text-align:left\">10m</td>\n",
        "                <td style=\"text-align:left\">2021</td>\n",
        "                <td style=\"text-align:left\">global</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"text-align:left\"><a\n",
        "                        href=\"https://developers.google.com/earth-engine/datasets/catalog/MERIT_Hydro_v1_0_1\">MERIT\n",
        "                        Hydro</a></td>\n",
        "                <td style=\"text-align:left\">Flood direction and hydrography dataset.</td>\n",
        "                <td style=\"text-align:left\">University of Tokyo</td>\n",
        "                <td style=\"text-align:left\">~90m</td>\n",
        "                <td style=\"text-align:left\">1987 – 2017</td>\n",
        "                <td style=\"text-align:left\">global</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"text-align:left\"><a\n",
        "                        href=\"https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_HOURLY\">ERA5-Land\n",
        "                        Hourly</a></td>\n",
        "                <td style=\"text-align:left\">Hourly climate reanalysis variables.</td>\n",
        "                <td style=\"text-align:left\">Copernicus/ECMWF</td>\n",
        "                <td style=\"text-align:left\">~11km</td>\n",
        "                <td style=\"text-align:left\">1950 – present</td>\n",
        "                <td style=\"text-align:left\">global</td>\n",
        "            </tr>\n",
        "            <tr>\n",
        "                <td style=\"text-align:left\"><a href=\"https://gee-community-catalog.org/projects/isric/\">Soil Grids 250m\n",
        "                        v2.0</a></td>\n",
        "                <td style=\"text-align:left\">Soil property and class predictions.</td>\n",
        "                <td style=\"text-align:left\">ISRIC</td>\n",
        "                <td style=\"text-align:left\">250m</td>\n",
        "                <td style=\"text-align:left\">Static (v2.0)</td>\n",
        "                <td style=\"text-align:left\">global</td>\n",
        "            </tr>\n",
        "        </tbody>\n",
        "    </table>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After checking on our input data in the catalogs, we want to visualize them on a map. *[geemap.Map](https://geemap.org/geemap/#geemap.geemap.Map)* provides a class for interactive mapping of GEE data in a Jupyter Notebook.\n",
        "\n",
        "In the cell below, initialize a map with some basemaps and add the our historic flood layer. To correctly visualize the flood footprints, we need to ensure that we only include temporary inundation (the flood event) and not the permanent water bodies. To achieve this, we define a function *subtractPermanentWater*, which we will then run over every single image in our *ee.ImageCollection* of global flood events."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Try to understand the logic in the <em>subtractPermanentWater</em> function in the cell below.\n",
        "  <ol style=\"margin-top: 10px; margin-bottom: 0;\">\n",
        "    <li>How exactly does it remove the permanent water bodies from the floods? </li>\n",
        "    <li>Why are we only using classes from the <em>ee</em> library and not some other Python library such as <em>numpy</em> or <em>xarray</em>?</li>\n",
        "    <li>What do we achieve by calling <code>.sum()</code> in <code>flood = globalFlood.map(subtractPermanentWater).sum()</code> in row 6?</li>\n",
        "  </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #1fbd5bff;\">\n",
        "    <strong style=\"color: #1fbd5bff;\">Solution:</strong>\n",
        "    <ol>\n",
        "        <li>\n",
        "            <p>The core logic of that function sits in <code>flood.multiply(perm.eq(0))</code></p>\n",
        "            <ul>\n",
        "                <li>\n",
        "                    <p><code>perm.eq(0)</code> (mask creation):</p>\n",
        "                    <ul>\n",
        "                        <li>The <em>jrc_perm_water</em> band (permanent water) has a value of 1 for permanent water and 0\n",
        "                            for no permanent water.</li>\n",
        "                        <li>The <code>.eq(0)</code> method performs a pixel-by-pixel comparison:<ul>\n",
        "                                <li>Where permanent water exists (perm == 1), the result is 0 (False).</li>\n",
        "                                <li>Where permanent water does not exist (perm == 0), the result is 1 (True).</li>\n",
        "                            </ul>\n",
        "                        </li>\n",
        "                        <li>Result: an intermediate binary mask where 1 marks the land/non-permanent water areas, and 0\n",
        "                            marks the permanent water areas.</li>\n",
        "                    </ul>\n",
        "                </li>\n",
        "                <li>\n",
        "                    <p><code>flood.multiply(...)</code> (mask application):</p>\n",
        "                    <ul>\n",
        "                        <li>This performs element-wise multiplication between the original flood band (which is 1 for\n",
        "                            flooded areas) and the binary mask created in step 1.</li>\n",
        "                        <li>If a pixel is a flood pixel:<ul>\n",
        "                                <li>Case A (transient flood): if the flood occurred on land (mask is 1), then 1*1=1 (stays\n",
        "                                    flooded).</li>\n",
        "                                <li>Case B (permanent water): if the flood occurred on permanent water (mask is 0), then\n",
        "                                    1*0=0 (becomes non-flooded/masked out).</li>\n",
        "                            </ul>\n",
        "                        </li>\n",
        "                        <li>Result: a new raster where the original flood areas are preserved only if they are outside the\n",
        "                            permanent water body mask.</li>\n",
        "                    </ul>\n",
        "                </li>\n",
        "            </ul>\n",
        "        </li>\n",
        "        <li>By using GEE functionality, we execute all computations on the GEE servers, benefiting from GEE&#39;s resources,\n",
        "            optimisation and parallelisation. Also, GEE is a lazy system, which means that operations are defined and\n",
        "            queued, but no computations are executed on the data until a specific action, like displaying, downloading, or\n",
        "            printing a result, forces the evaluation. In short: GEE only computes what is needed. Because of this approach\n",
        "            and its optimisation, GEE is much more efficient than our Colab environment.</li>\n",
        "        <li>The <code>sum()</code> function is a reducer that collapses the entire <em>ee.ImageCollection</em> into a single\n",
        "            <em>ee.Image</em>. Here, it calculates the total number of times a pixel was flooded after permanent water\n",
        "            bodies were masked out.</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Run the cell below and check out the map.\n",
        "  <ol>\n",
        "    <li>Try adding a few more of our input datasets to the map as additional layers so you can explore them visually. We are interested in elevation, landcover, upstream drainage area, precipitation and runoff potential. You can find the geemap documentation <a href=\"https://geemap.org/\">here</a>. If you are blocked, you can check my solution in <a href=\"https://github.com/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee_master.ipynb\">this notebook</a>.</li>\n",
        "    <li>How are the floods distributed? Are there geographies without any or with only a few floods?</li>\n",
        "  </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #1fbd5bff;\">\n",
        "<strong style=\"color: #1fbd5bff;\">Solution:</strong>\n",
        "  <ol>\n",
        "    <li>See cell below for code.</li>\n",
        "    <li>The dataset covers flood across all contintents. Most flood events are near coastlines. Data in Africa is sparse.</li>\n",
        "  </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmwnW78Of3Tq"
      },
      "outputs": [],
      "source": [
        "## subtract the permanent water bodies from the flooded areas\n",
        "def subtractPermanentWater(img):\n",
        "  flood = img.select('flooded')\n",
        "  perm = img.select('jrc_perm_water')\n",
        "  return flood.multiply(perm.eq(0))\n",
        "flood = globalFlood.map(subtractPermanentWater).sum()\n",
        "\n",
        "## initialize map and add some basemaps\n",
        "# see https://stackoverflow.com/a/33023651 for Google basemap list\n",
        "Map = geemap.Map(center=[27, -81], zoom=7, basemap='CartoDB.DarkMatter')\n",
        "Map.add_basemap('CartoDB.Positron', show=False)\n",
        "Map.add_tile_layer(\"https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}\", name=\"Google.Roadmap\", attribution=\"Google\", shown=False)\n",
        "Map.add_tile_layer(\"https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}\", name=\"Google.Satellite\", attribution=\"Google\", shown=False)\n",
        "\n",
        "## add historic floods\n",
        "flood_vis = {'min':0, 'max':10, 'palette':cm.palettes.Blues}\n",
        "Map.add_layer(flood.selfMask(), flood_vis, 'Historic floods')\n",
        "Map.add_colorbar(flood_vis, label=\"Number of floods\", layer_name=\"Historic floods\")\n",
        "\n",
        "## add elevation\n",
        "elevation_vis = {'min':0, 'max':3000, 'palette':cm.palettes.dem}\n",
        "Map.addLayer(dem.mosaic(), elevation_vis, 'Elevation', shown=False)\n",
        "Map.add_colorbar(elevation_vis, label=\"Elevation [m]\", layer_name=\"Elevation\")\n",
        "\n",
        "## add landcover\n",
        "landcover_vis = {'bands':['Map']}\n",
        "Map.addLayer(landcover.first(), landcover_vis, 'Landcover', shown=False)\n",
        "Map.add_legend(title=\"Landcover\", builtin_legend=\"ESA_WorldCover\", layer_name='Landcover')\n",
        "\n",
        "## add upstream drainage area\n",
        "upa_vis = {'min':0, 'max':10, 'palette':cm.palettes.Purples}\n",
        "Map.addLayer(hydro.select('upa'), upa_vis, 'Upstream drainage area', shown=False)\n",
        "Map.add_colorbar(upa_vis, label=\"Upstream drainage area [km^2]\", layer_name=\"Upstream drainage area\")\n",
        "\n",
        "## add precipitation\n",
        "prec_vis = {'min':0, 'max':5, 'palette':cm.palettes.turbo}\n",
        "Map.addLayer(prec.filter(ee.Filter.date('2024-10-01', '2024-10-31')).sum(), prec_vis, 'Precipitation', shown=False)\n",
        "Map.add_colorbar(prec_vis, label=\"Precipitation [m]\", layer_name=\"Precipitation\")\n",
        "\n",
        "## add runoff potential\n",
        "ee_class_table = \"\"\"\n",
        "Value\tColor\tDescription\n",
        "1\tedf8e9\tHSG-A: low runoff potential (>90% sand and <10% clay)\n",
        "2\tbae4b3\tHSG-B: moderately low runoff potential (50-90% sand and 10-20% clay)\n",
        "3\t74c476\tHSG-C: moderately high runoff potential (<50% sand and 20-40% clay)\n",
        "4\t238b45\tHSG-D: high runoff potential (<50% sand and >40% clay)\n",
        "\"\"\"\n",
        "runoff_legend = geemap.legend_from_ee(ee_class_table)\n",
        "runoff_vis = {'min':0, 'max':4, 'palette':list(runoff_legend.values())}\n",
        "Map.addLayer(runoffPotential, runoff_vis, 'Runoff potential', shown=False)\n",
        "Map.add_legend(\"Runoff potential\", legend_dict=runoff_legend, layer_name=\"Runoff potential\")\n",
        "\n",
        "## display map\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv7ybAUMSDmx"
      },
      "source": [
        "---\n",
        "## Training dataset\n",
        "\n",
        "We are now somewhat familiar with out input data that we want to use for model training. However, the data are different raster datasets with different band information and various resolutions.\n",
        "\n",
        "In the next cell, we define the logic to create a point dataset where every point is enriched with the corresponding pixel values from our input data. For this, we define two helper functions *pointQuery* and *removeProperty*, which we then use in our main function *createSample*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Run the cell below and try to understand the code.\n",
        "    <ol>\n",
        "        <li>What is the general logic in <em>createSample</em>?</li>\n",
        "        <li>Why are we using <em>ee.Image.stratifiedSample</em> in line 70 instead of using the much faster\n",
        "            <em>ee.Image.Sample</em> method?</li>\n",
        "        <li>Why are we using the complicated GEE methods in lines 65-76 and 90-94 instead of simply using plain Python?</li>\n",
        "        <li>What does <em>ee.FeatureCollection.map</em> do? Why do we not just write a simple for-loop instead?</li>\n",
        "        <li>Why do we normalize the elevation values?</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #1fbd5bff;\">\n",
        "<strong style=\"color: #1fbd5bff;\">Solution:</strong>\n",
        "<ol>\n",
        "    <li>See comments in the function code.</li>\n",
        "    <li><em>stratifiedSample</em> samples the same number of locations within each class. Since our flood footprints\n",
        "        ostly contain non-flooded pixels, using <em>stratifiedSample</em> is a convenient way to avoid oversampling\n",
        "        non-flooded pixels. However, there might also be a risk of <em>stratifiedSample</em> oversampling certain\n",
        "        flooded areas if the flood footprint is very small.</li>\n",
        "    <li>We want to execute all the code in GEE itself so we can benefit from its optimization and parallelisation. If we\n",
        "        would use plain Python, we would need to fetch the info from GEE server into our Colab Runtime which would make\n",
        "        the whole process extremely inefficient.</li>\n",
        "    <li><em>map</em> iterates over a feature collection and applies an algorithm to each feature. This process is run in\n",
        "        parallel on the GEE server. Using a Python for-loop instead would loose the parallel execution and also create\n",
        "        all the problems mentioned in the last question.</li>\n",
        "    <li>We use a global flood dataset, but look at the individual events independently. We do not want to create a bias\n",
        "        towards the general elevation of the region where an event took place and are therefore normalizing the\n",
        "        elevation within each image (and therefore for each event).</li>\n",
        "</ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7fUtqOy6VTu"
      },
      "outputs": [],
      "source": [
        "def pointQuery(fc:ee.FeatureCollection, img:ee.Image, prop:str) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Returns pixel values at locations using a feature collection and an image.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  fc: : ee.FeatureCollection\n",
        "    Collection of points at which to query the image.\n",
        "  img : ee.Image\n",
        "    The image to query.\n",
        "  prop : str\n",
        "    Name of new property to hold the query results.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Input FeatureCollection with lookup values added as new property.\n",
        "  \"\"\"\n",
        "  fc = img.reduceRegions(collection=fc, reducer=ee.Reducer.first())\n",
        "  return fc.map(lambda feat: feat.set(prop, feat.get('first')))\n",
        "\n",
        "\n",
        "def removeProperty(fc:ee.FeatureCollection, prop:str) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Removes a property by name from a feature collection.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  fc : ee.FeatureCollection\n",
        "    Collection from which to remove the property.\n",
        "  prop : str\n",
        "    Property to remove.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Input collection without the removed property.\n",
        "  \"\"\"\n",
        "  selectProperties = fc.propertyNames().filter(ee.Filter.neq('item', prop))\n",
        "  return fc.select(selectProperties)\n",
        "\n",
        "\n",
        "def createSample(img:ee.Image) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Samples training dataset for a single flood image.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  img : ee.Image\n",
        "    Input image.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Sampled and enriched training data.\n",
        "  \"\"\"\n",
        "\n",
        "  ## subtract permanent water bodies from flooded areas\n",
        "  permanent = img.select('jrc_perm_water')\n",
        "  water = img.select('flooded')\n",
        "  flooded = water.subtract(permanent).gt(0)\n",
        "\n",
        "  ## get the total and maximum precipitation over 14 days prior to the event end date\n",
        "  end = img.getNumber('system:time_end')\n",
        "  start = end.subtract(1209600000) # timestamp in milliseconds: 60 * 60 * 24 * 14 * 1000\n",
        "  precSum = prec.filter(ee.Filter.date(start, end)).sum()\n",
        "  precMax = prec.filter(ee.Filter.date(start, end)).max()\n",
        "\n",
        "  ## sample equal number of flooded and non-flooded points\n",
        "  sample = flooded.stratifiedSample(numPoints=SAMPLE_SIZE, classBand='flooded', geometries=True)\n",
        "\n",
        "  ## add image id in case we want to join the event metadata later\n",
        "  sample = sample.map(lambda x: x.set('eventId', img.get('system:index')))\n",
        "\n",
        "  ## enrich sample by running point lookups on multiple datasets\n",
        "  sample = pointQuery(sample, dem.mosaic(), 'demElevationAbs')\n",
        "  sample = pointQuery(sample, ee.Terrain.aspect(dem.mosaic()), 'demAspect')\n",
        "  sample = pointQuery(sample, ee.Terrain.slope(dem.mosaic()), 'demSlope')\n",
        "  sample = pointQuery(sample, landcover.first(), 'landcover')\n",
        "  sample = pointQuery(sample, hydro.select('upa'), 'upa')\n",
        "  sample = pointQuery(sample, runoffPotential, 'runoffPot')\n",
        "  sample = pointQuery(sample, precSum, 'precSum')\n",
        "  sample = pointQuery(sample, precMax, 'precMax')\n",
        "\n",
        "  ## remove first-property\n",
        "  sample = sample.map(lambda feat: removeProperty(feat, 'first'))\n",
        "\n",
        "  ## normalize elevation\n",
        "  elevationRange = dem.mosaic().reduceRegion(geometry=img.geometry(), reducer=ee.Reducer.minMax())\n",
        "  min = ee.Number(elevationRange.get('DEM_min'))\n",
        "  max = ee.Number(elevationRange.get('DEM_max'))\n",
        "  def normalizeElevation(feat:ee.Feature) -> ee.Feature:\n",
        "    return feat.set('demElevationNorm', (ee.Number(feat.get('demElevationAbs')).subtract(min)).divide(max.subtract(min)))\n",
        "  sample = sample.filter(ee.Filter.notNull(ee.List(['demElevationAbs']))).map(normalizeElevation)\n",
        "\n",
        "  return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The last cell defined the functions to process flood event images and extract training samples with enriched features. We now want to execute those functions as a batch job and export the result to a GEE asset.\n",
        "\n",
        "The next cell defines the export task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6ErNPvdBZm5"
      },
      "outputs": [],
      "source": [
        "## create task to enrich sample and store the result as an asset\n",
        "properties = ['demAspect', 'demElevationAbs', 'demElevationNorm', 'demSlope', 'eventId', 'flooded', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa', '.geo']\n",
        "sample = globalFlood.map(createSample).flatten()\n",
        "sample = sample.filter(ee.Filter.notNull(properties)).distinct(properties)\n",
        "task = ee.batch.Export.table.toAsset(sample, description='flood475-sampling', assetId=f\"projects/{PROJECT_ID}/assets/flood475_sample\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And this cell actually runs it. It is run on GEE and there are several ways to monitor it. One way is to constantly request the task status from our notebook (the commented part in the cell below). However, this also blocks our notebook so we rather choose one of the other ways to monitor progress:\n",
        "- [GEE Code editor](https://code.earthengine.google.com/)\n",
        "- [Task Manager](https://code.earthengine.google.com/tasks)\n",
        "- [Tasks Page in the Cloud Console](https://console.cloud.google.com/earth-engine/tasks?project=ee-timwaldburger-flood475)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Run the cell below and check if your task is running via one of the different methods.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6I0aPqCXBIr"
      },
      "outputs": [],
      "source": [
        "## run and monitor the task\n",
        "task.start()\n",
        "# while task.active():\n",
        "#   ts = task.status()\n",
        "#   if ts['start_timestamp_ms']>0:\n",
        "#     s = round((ts['update_timestamp_ms']-ts['start_timestamp_ms'])/1000)\n",
        "#   else:\n",
        "#     s = round((ts['update_timestamp_ms']-ts['creation_timestamp_ms'])/1000)\n",
        "#   print(f\"task '{ts['description']}' is {ts['state']} for {s} seconds\")\n",
        "#   time.sleep(60)\n",
        "# task.status()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now import our exported asset and visualize our training data. Depending on your sample size, training may take up to 30 minutes or more. You can therefore load the training data I created previously by running the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## import the pre-created training dataset\n",
        "sample = ee.FeatureCollection(f\"projects/ee-timwaldburger-flood475/assets/flood475_sample\")\n",
        "\n",
        "## import your training dataset\n",
        "# sample = ee.FeatureCollection(f\"projects/{PROJECT_ID}/assets/flood475_sample\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Add the training locations to the map we created above. If you are blocked, you can check my solution in <a href=\"https://github.com/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee_master.ipynb\">this notebook</a>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGikkZOFV98p"
      },
      "outputs": [],
      "source": [
        "visParams = {\n",
        "    'color': '#FFFFFF',\n",
        "    'colorOpacity': 1,\n",
        "    'pointSize': 5,\n",
        "    'pointShape': 'circle',\n",
        "    'width': 2,\n",
        "    'lineType': 'solid',\n",
        "    'fillColorOpacity': 1,\n",
        "}\n",
        "Map.add_styled_vector(sample, column='flooded', palette=['#ffffbf', '#d7191c'], layer_name='Training data', **visParams)\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqUK7JJ68JfH"
      },
      "source": [
        "---\n",
        "## Model training\n",
        "\n",
        "We have now prepared our training data and are ready to train our model. To keep dependencies as simple as possible, we chose a [random forest](https://www.ibm.com/think/topics/random-forest), which is available within GEE from *[ee.Classifier.smileRandomForest](https://developers.google.com/earth-engine/apidocs/ee-classifier-smilerandomforest)*. We train the model using only 70 % of our test data and reserve the other 30 % for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6XMurxl8NJf"
      },
      "outputs": [],
      "source": [
        "## partition into 70% training and 30% validation samples\n",
        "sample = sample.randomColumn('random', seed=SEED)\n",
        "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
        "validation = sample.filter(ee.Filter.gte('random', 0.7))\n",
        "\n",
        "## train a random forest\n",
        "properties = ['demAspect', 'demElevationNorm', 'demSlope', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa']\n",
        "randomForest = ee.Classifier.smileRandomForest(10).setOutputMode('CLASSIFICATION')\n",
        "classifier = randomForest.train(\n",
        "    features=training,\n",
        "    classProperty='flooded',\n",
        "    inputProperties=properties\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The cell below calcualtes and prints some accuracy metrics on the training and the validation dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAbN6t2uMXlq"
      },
      "outputs": [],
      "source": [
        "# accuracy on training set\n",
        "trainConfusionMatrix = classifier.confusionMatrix()\n",
        "trainFscores = trainConfusionMatrix.fscore().getInfo()\n",
        "print(f\"train accuracy: {trainConfusionMatrix.accuracy().getInfo():.3f}\")\n",
        "print(f\"train f-score non-flooded: {trainFscores[0]:.3f}\")\n",
        "print(f\"train f-score flooded: {trainFscores[1]:.3f}\")\n",
        "\n",
        "# accuracy on validation set\n",
        "testConfusionMatrix = validation.classify(classifier).errorMatrix('flooded', 'classification')\n",
        "testFscores = testConfusionMatrix.fscore().getInfo()\n",
        "print(f\"validation accuracy: {testConfusionMatrix.accuracy().getInfo():.3f}\")\n",
        "print(f\"validation f-score non-flooded: {testFscores[0]:.3f}\")\n",
        "print(f\"validation f-score flooded: {testFscores[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Check the metrics returned by the cell above.\n",
        "    <ol>\n",
        "        <li>What do accuracy and F1-Score describe?</li>\n",
        "        <li>Do you think the model performs well given those results?</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #1fbd5bff;\">\n",
        "<strong style=\"color: #1fbd5bff;\">Solution:</strong>\n",
        "  <ol>\n",
        "      <li>Accuracy: How often is the model right? An accuracy of 0.9 is generally considered good in many machine learning\n",
        "          contexts. It means that your model makes the correct prediction 90% of the time.</li>\n",
        "      <li>F1-Score: Metric that combines precision and recall into a single value. It provides a balanced measure of a\n",
        "          model&#39;s performance, considering both the accuracy of positive predictions (precision) and the ability to\n",
        "          identify all positive instances (recall). An F1-score of 0.8 is generally considered good. It indicates that\n",
        "          your model is performing well in terms of both precision and recall. <ul>\n",
        "              <li>Recall: How many positive predictions can the model identify?</li>\n",
        "              <li>Precision: How often are positive predictions correct?</li>\n",
        "          </ul>\n",
        "      </li>\n",
        "      <li>\n",
        "          <table>\n",
        "              <thead>\n",
        "                  <tr>\n",
        "                      <th style=\"text-align:left\">Metric</th>\n",
        "                      <th style=\"text-align:left\">Training Score</th>\n",
        "                      <th style=\"text-align:left\">Validation Score</th>\n",
        "                      <th style=\"text-align:left\">Difference</th>\n",
        "                      <th style=\"text-align:left\">Key Observation</th>\n",
        "                  </tr>\n",
        "              </thead>\n",
        "              <tbody>\n",
        "                  <tr>\n",
        "                      <td style=\"text-align:left\"><strong>Accuracy</strong></td>\n",
        "                      <td style=\"text-align:left\">0.923 (92.3%)</td>\n",
        "                      <td style=\"text-align:left\">0.820 (82.0%)</td>\n",
        "                      <td style=\"text-align:left\"><strong>10.3%</strong></td>\n",
        "                      <td style=\"text-align:left\">Significant gap (Overfitting)</td>\n",
        "                  </tr>\n",
        "                  <tr>\n",
        "                      <td style=\"text-align:left\"><strong>F-score (Non-Flooded)</strong></td>\n",
        "                      <td style=\"text-align:left\">0.934</td>\n",
        "                      <td style=\"text-align:left\">0.850</td>\n",
        "                      <td style=\"text-align:left\">8.4%</td>\n",
        "                      <td style=\"text-align:left\">Good on majority class</td>\n",
        "                  </tr>\n",
        "                  <tr>\n",
        "                      <td style=\"text-align:left\"><strong>F-score (Flooded)</strong></td>\n",
        "                      <td style=\"text-align:left\">0.907</td>\n",
        "                      <td style=\"text-align:left\">0.775</td>\n",
        "                      <td style=\"text-align:left\"><strong>13.2%</strong></td>\n",
        "                      <td style=\"text-align:left\">Poor on minority class</td>\n",
        "                  </tr>\n",
        "              </tbody>\n",
        "          </table>\n",
        "          <ul>\n",
        "              <li>Overfitting (main issue)<ul>\n",
        "                      <li>The large drop in accuracy from 92.3% on the training data to 82.0% on the validation data is the key\n",
        "                          takeaway.<ul>\n",
        "                              <li>What it means: the random forest is not learning the general patterns of flood vs. non-flood\n",
        "                                  events but instead, it is memorizing the noise and specific details of the training dataset.\n",
        "                                  When presented with new, unseen data (the validation set), its performance suffers\n",
        "                                  significantly.</li>\n",
        "                              <li>Why it happens: random forests can easily overfit, especially if you have deep trees, a large\n",
        "                                  number of trees, or a small training dataset that lacks diversity.</li>\n",
        "                          </ul>\n",
        "                      </li>\n",
        "                  </ul>\n",
        "              </li>\n",
        "              <li>Class imbalance<ul>\n",
        "                      <li>The F-scores highlight how the model performs on the two different classes:<ul>\n",
        "                              <li>F-score for non-flooded (majority class): the score is higher (0.850 validation) and the gap is\n",
        "                                  smaller (8.4%). This means the model is relatively reliable at identifying non-flooded areas.\n",
        "                              </li>\n",
        "                          </ul>\n",
        "                      </li>\n",
        "                      <li>F-score for flooded (minority class): the score is significantly lower (0.775 validation) and the gap is\n",
        "                          the largest (13.2%). <ul>\n",
        "                              <li>What it means: the model struggles most to correctly identify actual flood events on new data.\n",
        "                                  This is where we see the biggest generalization failure.</li>\n",
        "                              <li>A lower F-score on the minority class is a common sign of class imbalance, where the model\n",
        "                                  focuses on optimizing for the more frequent (non-flooded) outcomes.</li>\n",
        "                          </ul>\n",
        "                      </li>\n",
        "                  </ul>\n",
        "              </li>\n",
        "          </ul>\n",
        "      </li>\n",
        "  </ol>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us try once more by setting some parameters to address the overfitting issue. We will not worry to much about class imbalance since we have used stratified sampling to ensure same number of test locations per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## train another random forest with parameters to control overfitting\n",
        "properties = ['demAspect', 'demElevationNorm', 'demSlope', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa']\n",
        "randomForest = ee.Classifier.smileRandomForest(\n",
        "    numberOfTrees=50,             # sufficient ensemble size\n",
        "    maxNodes=32,                  # controls tree complexity (prevents deep memorization)\n",
        "    minLeafPopulation=5,          # ensures leaf nodes have enough samples (improves robustness)\n",
        "    bagFraction=0.63,             # recommended fraction for sampling\n",
        ").setOutputMode('CLASSIFICATION')\n",
        "classifier = randomForest.train(\n",
        "    features=training,\n",
        "    classProperty='flooded',\n",
        "    inputProperties=properties\n",
        ")\n",
        "\n",
        "# accuracy on training set\n",
        "trainConfusionMatrix = classifier.confusionMatrix()\n",
        "trainFscores = trainConfusionMatrix.fscore().getInfo()\n",
        "print(f\"train accuracy: {trainConfusionMatrix.accuracy().getInfo():.3f}\")\n",
        "print(f\"train f-score non-flooded: {trainFscores[0]:.3f}\")\n",
        "print(f\"train f-score flooded: {trainFscores[1]:.3f}\")\n",
        "\n",
        "# accuracy on validation set\n",
        "testConfusionMatrix = validation.classify(classifier).errorMatrix('flooded', 'classification')\n",
        "testFscores = testConfusionMatrix.fscore().getInfo()\n",
        "print(f\"validation accuracy: {testConfusionMatrix.accuracy().getInfo():.3f}\")\n",
        "print(f\"validation f-score non-flooded: {testFscores[0]:.3f}\")\n",
        "print(f\"validation f-score flooded: {testFscores[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Check the metrics returned by the new model.\n",
        "    <ol>\n",
        "        <li>Did we improve our model?</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #1fbd5bff;\">\n",
        "<strong style=\"color: #1fbd5bff;\">Solution:</strong>\n",
        "  <table>\n",
        "      <thead>\n",
        "          <tr>\n",
        "              <th style=\"text-align:left\">Metric</th>\n",
        "              <th style=\"text-align:left\">Training Score</th>\n",
        "              <th style=\"text-align:left\">Validation Score</th>\n",
        "              <th style=\"text-align:left\">Difference</th>\n",
        "              <th style=\"text-align:left\">Key Observation</th>\n",
        "          </tr>\n",
        "      </thead>\n",
        "      <tbody>\n",
        "          <tr>\n",
        "              <td style=\"text-align:left\"><strong>Accuracy</strong></td>\n",
        "              <td style=\"text-align:left\">0.660 (66.0%)</td>\n",
        "              <td style=\"text-align:left\">0.658 (65.8%)</td>\n",
        "              <td style=\"text-align:left\"><strong>0.2%</strong></td>\n",
        "              <td style=\"text-align:left\">Excellent Generalization! (Overfitting Solved)</td>\n",
        "          </tr>\n",
        "          <tr>\n",
        "              <td style=\"text-align:left\"><strong>F-score (Non-Flooded)</strong></td>\n",
        "              <td style=\"text-align:left\">0.752</td>\n",
        "              <td style=\"text-align:left\">0.751</td>\n",
        "              <td style=\"text-align:left\">0.1%</td>\n",
        "              <td style=\"text-align:left\">Generalizes well on majority class</td>\n",
        "          </tr>\n",
        "          <tr>\n",
        "              <td style=\"text-align:left\"><strong>F-score (Flooded)</strong></td>\n",
        "              <td style=\"text-align:left\">0.459</td>\n",
        "              <td style=\"text-align:left\">0.455</td>\n",
        "              <td style=\"text-align:left\">0.4%</td>\n",
        "              <td style=\"text-align:left\"><strong>Extremely Low</strong> Predictive Power</td>\n",
        "          </tr>\n",
        "      </tbody>\n",
        "  </table>\n",
        "  <ul>\n",
        "      <li>Good news: overfitting is solved!<ul>\n",
        "              <li>The difference between our training and validation accuracy has collapsed from 10.3% down to just 0.2%\n",
        "                  (0.660 vs. 0.658). Similarly, the F-scores for both classes are almost identical between training and\n",
        "                  validation.</li>\n",
        "              <li>This confirms that our model is now learning general patterns and is robust when applied to unseen data.\n",
        "                  The choice of parameters like lower <em>maxNodes</em> and higher <em>minLeafPopulation</em> successfully\n",
        "                  prevented the trees from memorizing the noise.</li>\n",
        "          </ul>\n",
        "      </li>\n",
        "      <li>The bad news: low predictive power<ul>\n",
        "              <li>Overall accuracy (0.658): an accuracy of 65.8% is only marginally better than random guessing (50%) and\n",
        "                  certainly not sufficient for a reliable flood prediction.</li>\n",
        "              <li>An F-score of 0.455 means the model is failing to correctly and reliably predict flood events. This low\n",
        "                  score suggests our model has a very poor balance of precision (avoiding false alarms) and recall\n",
        "                  (catching all actual floods) for the minority class.</li>\n",
        "          </ul>\n",
        "      </li>\n",
        "      <li>What next?<ul>\n",
        "              <li>Given that the model is stable but poorly accurate, the problem is most likely not in the model&#39;s\n",
        "                  complexity, but in the quality and discriminatory power of our input features. Our next step would\n",
        "                  therefore be to improve our training data by revisiting the input datasets, analyzing ther predictive\n",
        "                  value, removing unnecessary ones and adding new ones. We will not do that here, but proceed with\n",
        "                  prediction.</li>\n",
        "          </ul>\n",
        "      </li>\n",
        "  </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZAwkZyHCt-k"
      },
      "source": [
        "---\n",
        "## Prediction\n",
        "\n",
        "We know that our model is flawed, but let's still go ahead and run some predictions.\n",
        "\n",
        "The cell below defined the *predict* function, which takes a region of interest and a classifier (our random forest) as input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Try to understand the code in the cell below.\n",
        "    <ol>\n",
        "        <li>What does the <em>predict</em> function do exactly?</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #1fbd5bff;\">\n",
        "<strong style=\"color: #1fbd5bff;\">Solution:</strong>\n",
        "  <ol>\n",
        "    <li>The <em>predict </em>function creates a composite image by combining all the datasets we used for model training. It normalizes the elevation and aggregates precipitation. It then classifies every pixel in the composite using the pre-trained model.</li>\n",
        "  </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrmCVjlIDQZp"
      },
      "outputs": [],
      "source": [
        "def predict(roi: ee.Geometry, classifier: ee.Classifier) -> ee.Image:\n",
        "  \"\"\"\n",
        "  Predict flood probability for a given region of interest.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  roi : ee.Geometry\n",
        "    Region of interest.\n",
        "  classifier : ee.Classifier\n",
        "    Trained classifier.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.Image\n",
        "    Flood probabilities.\n",
        "  \"\"\"\n",
        "\n",
        "  ## normalize elevation\n",
        "  elevationRange = dem.mosaic().reduceRegion(geometry=roi, reducer=ee.Reducer.minMax(), scale=30, bestEffort=True)\n",
        "  min = ee.Number(elevationRange.get('DEM_min'))\n",
        "  max = ee.Number(elevationRange.get('DEM_max'))\n",
        "\n",
        "  ## calculate start and end data for precipitation data aggregation\n",
        "  end = ee.Date('2024-10-31T00:00:00').millis()\n",
        "  start = end.subtract(1209600000) # timestamp in milliseconds: 60 * 60 * 24 * 14 * 1000\n",
        "\n",
        "  ## create composite of all relevant datasets\n",
        "  composite = ee.Image.cat(\n",
        "      ee.Terrain.aspect(dem.mosaic()),\n",
        "      dem.mosaic().unitScale(min, max),\n",
        "      ee.Terrain.slope(dem.mosaic()),\n",
        "      landcover.first(),\n",
        "      prec.filter(ee.Filter.date(start, end)).max(),\n",
        "      prec.filter(ee.Filter.date(start, end)).sum(),\n",
        "      runoffPotential,\n",
        "      hydro.select('upa')\n",
        "  ).rename(properties)\n",
        "\n",
        "  ## classify the composite\n",
        "  classifier = classifier.setOutputMode('MULTIPROBABILITY')\n",
        "  classified = composite.classify(classifier).clip(roi)\n",
        "  probabilities = classified.arrayFlatten([['non-flooded', 'flooded']])\n",
        "  probability = probabilities.select('flooded')\n",
        "\n",
        "  return probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are ready to make predictions. For this, we call our *predict* function for a given region of interest using our random forest.\n",
        "\n",
        "<div style=\"padding: 15px; border-left: 6px solid #e12525ff;\">\n",
        "  <strong style=\"color: #e12525ff;\">Warning:</strong> The cell below uses the map bounds of our map where we explored the data as the extent for which to compute predictions. Make sure to zoom to a relatively small area to avoid long running computations.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HgIVRX3f6J3"
      },
      "outputs": [],
      "source": [
        "## run prediction for current map bounds\n",
        "probability = predict(roi=ee.Geometry.BBox(*Map.getBounds()), classifier=classifier)\n",
        "\n",
        "## update mask to exclude permanent water\n",
        "permanentWater = globalFlood.select('jrc_perm_water').mosaic()\n",
        "probability = probability.updateMask(permanentWater.neq(1))\n",
        "\n",
        "## update the map\n",
        "probability_vis = {'min':0, 'max':1, 'palette':cm.palettes.cividis}\n",
        "Map.addLayer(probability.selfMask(), probability_vis, 'Flooded probability')\n",
        "Map.add_colorbar(probability_vis, label=\"Flooded probability\", layer_name=\"Flooded probability\", font_size=9)\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb2D0kRqrZHJ"
      },
      "source": [
        "---\n",
        "## Feedback\n",
        "\n",
        "Providing a 2 minute feedback would help me to improve the exercise.\n",
        "Please run the cell below to display a Google Form where you can provide your feedback. I will not collect your mail address so the feedback is anonymous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxH4RUe4rW3I"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<iframe src=\"https://docs.google.com/forms/d/e/1FAIpQLScg8j6ORkqgWw4QEHpkeOy2PxYKSdgop3PPvaA1_WT54igFIA/viewform?embedded=true\" width=\"640\" height=\"1304\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading…</iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TebjhRrVgpVt"
      },
      "source": [
        "---\n",
        "## Bonus: run country-scale prediction\n",
        "The code below runs the trained model for all of Switzerland at 30 m resolution and exports the result to GEE. It runs in about 20 minutes. No need to run in the lab, but feel free to try it out and play around with different models, geographies and settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXdcJDjWgVrY"
      },
      "outputs": [],
      "source": [
        "## get country shape\n",
        "countries = ee.FeatureCollection('WM/geoLab/geoBoundaries/600/ADM0')\n",
        "ch = countries.filterMetadata('shapeName', 'equals', 'Switzerland')\n",
        "\n",
        "## run prediction for Switzerland\n",
        "flooded_prob = predict(roi=ch.geometry(), classifier=classifier)\n",
        "\n",
        "## update the map\n",
        "flooded_prob_vis = {'min':0, 'max':1, 'palette':cm.palettes.cividis}\n",
        "Map.addLayer(flooded_prob.selfMask(), flooded_prob_vis, 'Flooded probability')\n",
        "Map.add_colorbar(flooded_prob_vis, label=\"CH flooded probability\", layer_name=\"CH flooded probability\", font_size=9)\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rWlXxOGfqQM"
      },
      "outputs": [],
      "source": [
        "## create export task\n",
        "task = ee.batch.Export.image.toAsset(\n",
        "  flooded_prob,\n",
        "  description='flood475-ch-prediction',\n",
        "  assetId=f\"projects/{PROJECT_ID}/assets/flood475_ch_prediction\",\n",
        "  scale=30,\n",
        "  maxPixels=500_000_000\n",
        ")\n",
        "\n",
        "## run and monitor the task\n",
        "task.start()\n",
        "while task.active():\n",
        "  ts = task.status()\n",
        "  if ts['start_timestamp_ms']>0:\n",
        "    s = round((ts['update_timestamp_ms']-ts['start_timestamp_ms'])/1000)\n",
        "  else:\n",
        "    s = round((ts['update_timestamp_ms']-ts['creation_timestamp_ms'])/1000)\n",
        "  print(f\"task '{ts['description']}' is {ts['state']} for {s} seconds\")\n",
        "  time.sleep(60)\n",
        "task.status()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
