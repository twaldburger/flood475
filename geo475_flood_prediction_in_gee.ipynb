{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWQwO95HL-yd"
      },
      "source": [
        "# Geo475 - Flood prediction in Google Earth Engine\n",
        "\n",
        "Go through the notebook and run the cells. Try to understand the code and the overall approach.  \n",
        "Feel free to update code where you see room for improvement and do not hesitate to ask questions.\n",
        "\n",
        "There are several tasks in the notebook, which are intended to trigger exploration and discussions. Please try to solve them but do not spend too much time on them. The goal is to understand the process and the code - solving all the tasks is secondary. \n",
        "\n",
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Tasks are marked like this.\n",
        "</div> \n",
        "\n",
        "The notebook with answers to the tasks can be found [here](https://github.com/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee_master.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtw_pQpNp1J"
      },
      "source": [
        "---\n",
        "## Setup\n",
        "\n",
        "We use the *[Earth Engine](https://developers.google.com/earth-engine/guides/python_install)* and the *[geemap](https://geemap.org/)* Python libraries to interact with GEE. *geemap* was originally created because the offical *ee* library had relatively little documentation and limited functionality while *geemap* enables users to easily analyze and visualize Earth Engine datasets interactively within a Jupyter-based environment.\n",
        "\n",
        "In this first code cell, we are importing our dependencies, setting some global variables and authenticating with GEE. All dependencies are already pre-installed in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "munACIb96Vfd"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import geemap\n",
        "import geemap.colormaps as cm\n",
        "import time\n",
        "\n",
        "## set some parameters, please update with your project id\n",
        "PROJECT_ID = '' # your GEE project id\n",
        "SAMPLE_SIZE = 100 # number of training locations per flood event and class\n",
        "SEED = 3414 # for reproducible results\n",
        "\n",
        "## connect to GEE\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except ee.EEException:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl1rsslKSJ7v"
      },
      "source": [
        "---\n",
        "## Data exploration and visualization\n",
        "\n",
        "GEE is built around two fundamental classes to represent raster and vector data: *[ee.Image](https://developers.google.com/earth-engine/apidocs/ee-image)* represents a single raster image while *[ee.Feature](https://developers.google.com/earth-engine/apidocs/ee-feature)* represents a geometry. Multiple images or geometries are represented as *[ee.ImageCollection](https://developers.google.com/earth-engine/apidocs/ee-imagecollection)* or as *[ee.FeatureCollection](https://developers.google.com/earth-engine/apidocs/ee-featurecollection)*.\n",
        "\n",
        "The main catalogs for GEE data are the official [Earth Engine Data Catalog](https://developers.google.com/earth-engine/datasets) and the community-maintained [awesome-gee-community-catalog](https://gee-community-catalog.org/). The Earth Engine Data Catalog stores over 90 petabytes of data and over 1'000 datasets while the awesome-gee-community-catalog stores about 500 terabytes of data and around 4'000 datasets. One of the big benefits of this data is, that they are curated, meaning that they have already been pre-processed and ingested and are ready for analysis. All we need to do is to select and use them.\n",
        "\n",
        "In the cell below, we select a few input datasets that we will be using to sample our training data for the model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBHxsikA6Vbh"
      },
      "outputs": [],
      "source": [
        "## define the datasets from which to derive the input features\n",
        "globalFlood = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\")\n",
        "dem = ee.ImageCollection('COPERNICUS/DEM/GLO30') \\\n",
        "        .select('DEM')\n",
        "landcover = ee.ImageCollection('ESA/WorldCover/v200')\n",
        "hydro = ee.Image('MERIT/Hydro/v1_0_1')\n",
        "prec = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \\\n",
        "         .select('total_precipitation')\n",
        "runoffPotential = ee.Image('projects/sat-io/open-datasets/HiHydroSoilv2_0/Hydrologic_Soil_Group_250m') \\\n",
        "                    .remap([1, 2, 3, 4, 14, 24, 34], [1, 2, 3, 4, 1, 3, 4]) \\\n",
        "                    .select('remapped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMhp6-quctsy"
      },
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Check out the <a href=\"https://developers.google.com/earth-engine/datasets\" target=\"_blank\">Earth Engine Data Catalog</a> and the <a href=\"https://gee-community-catalog.org/\" target=\"_blank\">awesome-gee-community-catalog</a>.\n",
        "  <ul style=\"margin-top: 10px; margin-bottom: 0;\">\n",
        "    <li>How are they structured?</li>\n",
        "    <li>What information do they provide?</li>\n",
        "    <li>Can you find the datasets we intend to use?</li>\n",
        "    <li>What are the spatial and temporal resolution of \"our\" datasets?</li>\n",
        "  </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After checking on our input data in the catalogs, we want to visualize them on a map. *[geemap.Map](https://geemap.org/geemap/#geemap.geemap.Map)* provides a class for interactive mapping of GEE data in a Jupyter Notebook.\n",
        "\n",
        "In the cell below, initialize a map with some basemaps and add the our historic flood layer. To correctly visualize the flood footprints, we need to ensure that we only include temporary inundation (the flood event) and not the permanent water bodies. To achieve this, we define a function *subtractPermanentWater*, which we will then run over every single image in our *ee.ImageCollection* of global flood events."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Try to understand the logic in the <em>subtractPermanentWater</em> function in the cell below.\n",
        "  <ol style=\"margin-top: 10px; margin-bottom: 0;\">\n",
        "    <li>How exactly does it remove the permanent water bodies from the floods? </li>\n",
        "    <li>Why are we only using classes from the <em>ee</em> library and not some other Python library such as <em>numpy</em> or <em>xarray</em>?</li>\n",
        "    <li>What do we achieve by calling <code>.sum()</code> in <code>flood = globalFlood.map(subtractPermanentWater).sum()</code> in row 6?</li>\n",
        "  </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Run the cell below and check out the map.\n",
        "  <ol>\n",
        "    <li>Try adding a few more of our input datasets to the map as additional layers so you can explore them visually. We are interested in elevation, landcover, upstream drainage area, precipitation and runoff potential. You can find the geemap documentation <a href=\"https://geemap.org/\">here</a>. If you are blocked, you can check my solution in <a href=\"https://github.com/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee_master.ipynb\">this notebook</a>.</li>\n",
        "    <li>How are the floods distributed? Are there geographies without any or with only a few floods?</li>\n",
        "  </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmwnW78Of3Tq"
      },
      "outputs": [],
      "source": [
        "## subtract the permanent water bodies from the flooded areas\n",
        "def subtractPermanentWater(img):\n",
        "  flood = img.select('flooded')\n",
        "  perm = img.select('jrc_perm_water')\n",
        "  return flood.multiply(perm.eq(0))\n",
        "flood = globalFlood.map(subtractPermanentWater).sum()\n",
        "\n",
        "## initialize map and add some basemaps\n",
        "# see https://stackoverflow.com/a/33023651 for Google basemap list\n",
        "Map = geemap.Map(center=[27, -81], zoom=7, basemap='CartoDB.DarkMatter')\n",
        "Map.add_basemap('CartoDB.Positron', show=False)\n",
        "Map.add_tile_layer(\"https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}\", name=\"Google.Roadmap\", attribution=\"Google\", shown=False)\n",
        "Map.add_tile_layer(\"https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}\", name=\"Google.Satellite\", attribution=\"Google\", shown=False)\n",
        "\n",
        "## add historic floods\n",
        "flood_vis = {'min':0, 'max':10, 'palette':cm.palettes.Blues}\n",
        "Map.add_layer(flood.selfMask(), flood_vis, 'Historic floods')\n",
        "Map.add_colorbar(flood_vis, label=\"Number of floods\", layer_name=\"Historic floods\")\n",
        "\n",
        "## display map\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Training dataset\n",
        "\n",
        "We are now somewhat familiar with out input data that we want to use for model training. However, the data are different raster datasets with different band information and various resolutions.\n",
        "\n",
        "In the next cell, we define the logic to create a point dataset where every point is enriched with the corresponding pixel values from our input data. For this, we define two helper functions *pointQuery* and *removeProperty*, which we then use in our main function *createSample*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Run the cell below and try to understand the code.\n",
        "    <ol>\n",
        "        <li>What is the general logic in <em>createSample</em>?</li>\n",
        "        <li>Why are we using <em>ee.Image.stratifiedSample</em> in line 70 instead of using the much faster\n",
        "            <em>ee.Image.Sample</em> method?</li>\n",
        "        <li>Why are we using the complicated GEE methods in lines 65-76 and 90-94 instead of simply using plain Python?</li>\n",
        "        <li>What does <em>ee.FeatureCollection.map</em> do? Why do we not just write a simple for-loop instead?</li>\n",
        "        <li>Why do we normalize the elevation values?</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7fUtqOy6VTu"
      },
      "outputs": [],
      "source": [
        "def pointQuery(fc:ee.FeatureCollection, img:ee.Image, prop:str) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Returns pixel values at locations using a feature collection and an image.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  fc: : ee.FeatureCollection\n",
        "    Collection of points at which to query the image.\n",
        "  img : ee.Image\n",
        "    The image to query.\n",
        "  prop : str\n",
        "    Name of new property to hold the query results.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Input FeatureCollection with lookup values added as new property.\n",
        "  \"\"\"\n",
        "  fc = img.reduceRegions(collection=fc, reducer=ee.Reducer.first())\n",
        "  return fc.map(lambda feat: feat.set(prop, feat.get('first')))\n",
        "\n",
        "\n",
        "def removeProperty(fc:ee.FeatureCollection, prop:str) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Removes a property by name from a feature collection.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  fc : ee.FeatureCollection\n",
        "    Collection from which to remove the property.\n",
        "  prop : str\n",
        "    Property to remove.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Input collection without the removed property.\n",
        "  \"\"\"\n",
        "  selectProperties = fc.propertyNames().filter(ee.Filter.neq('item', prop))\n",
        "  return fc.select(selectProperties)\n",
        "\n",
        "\n",
        "def createSample(img:ee.Image) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Samples training dataset for a single flood image.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  img : ee.Image\n",
        "    Input image.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Sampled and enriched training data.\n",
        "  \"\"\"\n",
        "\n",
        "  ## subtract permanent water bodies from flooded areas\n",
        "  permanent = img.select('jrc_perm_water')\n",
        "  water = img.select('flooded')\n",
        "  flooded = water.subtract(permanent).gt(0)\n",
        "\n",
        "  ## get the total and maximum precipitation over 14 days prior to the event end date\n",
        "  end = img.getNumber('system:time_end')\n",
        "  start = end.subtract(1209600000) # timestamp in milliseconds: 60 * 60 * 24 * 14 * 1000\n",
        "  precSum = prec.filter(ee.Filter.date(start, end)).sum()\n",
        "  precMax = prec.filter(ee.Filter.date(start, end)).max()\n",
        "\n",
        "  ## sample equal number of flooded and non-flooded points\n",
        "  sample = flooded.stratifiedSample(numPoints=SAMPLE_SIZE, classBand='flooded', geometries=True)\n",
        "\n",
        "  ## add image id in case we want to join the event metadata later\n",
        "  sample = sample.map(lambda x: x.set('eventId', img.get('system:index')))\n",
        "\n",
        "  ## enrich sample by running point lookups on multiple datasets\n",
        "  sample = pointQuery(sample, dem.mosaic(), 'demElevationAbs')\n",
        "  sample = pointQuery(sample, ee.Terrain.aspect(dem.mosaic()), 'demAspect')\n",
        "  sample = pointQuery(sample, ee.Terrain.slope(dem.mosaic()), 'demSlope')\n",
        "  sample = pointQuery(sample, landcover.first(), 'landcover')\n",
        "  sample = pointQuery(sample, hydro.select('upa'), 'upa')\n",
        "  sample = pointQuery(sample, runoffPotential, 'runoffPot')\n",
        "  sample = pointQuery(sample, precSum, 'precSum')\n",
        "  sample = pointQuery(sample, precMax, 'precMax')\n",
        "\n",
        "  ## remove first-property\n",
        "  sample = sample.map(lambda feat: removeProperty(feat, 'first'))\n",
        "\n",
        "  ## normalize elevation\n",
        "  elevationRange = dem.mosaic().reduceRegion(geometry=img.geometry(), reducer=ee.Reducer.minMax())\n",
        "  min = ee.Number(elevationRange.get('DEM_min'))\n",
        "  max = ee.Number(elevationRange.get('DEM_max'))\n",
        "  def normalizeElevation(feat:ee.Feature) -> ee.Feature:\n",
        "    return feat.set('demElevationNorm', (ee.Number(feat.get('demElevationAbs')).subtract(min)).divide(max.subtract(min)))\n",
        "  sample = sample.filter(ee.Filter.notNull(ee.List(['demElevationAbs']))).map(normalizeElevation)\n",
        "\n",
        "  return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The last cell defined the functions to process flood event images and extract training samples with enriched features. We now want to execute those functions as a batch job and export the result to a GEE asset.\n",
        "\n",
        "The next cell defines the export task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6ErNPvdBZm5"
      },
      "outputs": [],
      "source": [
        "## create task to enrich sample and store the result as an asset\n",
        "properties = ['demAspect', 'demElevationAbs', 'demElevationNorm', 'demSlope', 'eventId', 'flooded', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa', '.geo']\n",
        "sample = globalFlood.map(createSample).flatten()\n",
        "sample = sample.filter(ee.Filter.notNull(properties)).distinct(properties)\n",
        "task = ee.batch.Export.table.toAsset(sample, description='flood475-sampling', assetId=f\"projects/{PROJECT_ID}/assets/flood475_sample\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And this cell actually runs it. It is run on GEE and there are several ways to monitor it. One way is to constantly request the task status from our notebook (the commented part in the cell below). However, this also blocks our notebook so we rather choose one of the other ways to monitor progress:\n",
        "- [GEE Code editor](https://code.earthengine.google.com/)\n",
        "- [Task Manager](https://code.earthengine.google.com/tasks)\n",
        "- [Tasks Page in the Cloud Console](https://console.cloud.google.com/earth-engine/tasks?project=ee-timwaldburger-flood475)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Run the cell below and check if your task is running via one of the different methods.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6I0aPqCXBIr"
      },
      "outputs": [],
      "source": [
        "## run and monitor the task\n",
        "task.start()\n",
        "# while task.active():\n",
        "#   ts = task.status()\n",
        "#   if ts['start_timestamp_ms']>0:\n",
        "#     s = round((ts['update_timestamp_ms']-ts['start_timestamp_ms'])/1000)\n",
        "#   else:\n",
        "#     s = round((ts['update_timestamp_ms']-ts['creation_timestamp_ms'])/1000)\n",
        "#   print(f\"task '{ts['description']}' is {ts['state']} for {s} seconds\")\n",
        "#   time.sleep(60)\n",
        "# task.status()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now import our exported assed and visualize our training data. Depending on your sample size, training may take up to 30 minutes or more. You can therefore load the training data I created previously by running the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## import the pre-created training dataset\n",
        "sample = ee.FeatureCollection(f\"projects/ee-timwaldburger-flood475/assets/flood475_sample\")\n",
        "\n",
        "## import your training dataset\n",
        "# sample = ee.FeatureCollection(f\"projects/{PROJECT_ID}/assets/flood475_sample\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Add the training locations to the map we created above. If you are blocked, you can check my solution in <a href=\"https://github.com/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee_master.ipynb\">this notebook</a>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Model training\n",
        "\n",
        "We have now prepared our training data and are ready to train our model. To keep dependencies as simple as possible, we chose a [random forest](https://www.ibm.com/think/topics/random-forest), which is available within GEE from *[ee.Classifier.smileRandomForest](https://developers.google.com/earth-engine/apidocs/ee-classifier-smilerandomforest)*. We train the model using only 70 % of our test data and reserve the other 30 % for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6XMurxl8NJf"
      },
      "outputs": [],
      "source": [
        "## import the training dataset\n",
        "sample = ee.FeatureCollection(f\"projects/{PROJECT_ID}/assets/flood475_sample\")\n",
        "# sample = ee.FeatureCollection(f\"projects/ee-timwaldburger-flood475/assets/flood475_sample\")\n",
        "\n",
        "## partition into 70% training and 30% validation samples\n",
        "sample = sample.randomColumn('random', seed=SEED)\n",
        "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
        "validation = sample.filter(ee.Filter.gte('random', 0.7))\n",
        "\n",
        "## train a random forest\n",
        "properties = ['demAspect', 'demElevationNorm', 'demSlope', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa']\n",
        "randomForest = ee.Classifier.smileRandomForest(10).setOutputMode('CLASSIFICATION')\n",
        "classifier = randomForest.train(\n",
        "    features=training,\n",
        "    classProperty='flooded',\n",
        "    inputProperties=properties\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The cell below calcualtes and prints some accuracy metrics on the training and the validation dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAbN6t2uMXlq"
      },
      "outputs": [],
      "source": [
        "# accuracy on training set\n",
        "trainConfusionMatrix = classifier.confusionMatrix()\n",
        "trainFscores = trainConfusionMatrix.fscore().getInfo()\n",
        "print(f\"train accuracy: {trainConfusionMatrix.accuracy().getInfo():.3f}\")\n",
        "print(f\"train f-score non-flooded: {trainFscores[0]:.3f}\")\n",
        "print(f\"train f-score flooded: {trainFscores[1]:.3f}\")\n",
        "\n",
        "# accuracy on validation set\n",
        "testConfusionMatrix = validation.classify(classifier).errorMatrix('flooded', 'classification')\n",
        "testFscores = testConfusionMatrix.fscore().getInfo()\n",
        "print(f\"validation accuracy: {testConfusionMatrix.accuracy().getInfo():.3f}\")\n",
        "print(f\"validation f-score non-flooded: {testFscores[0]:.3f}\")\n",
        "print(f\"validation f-score flooded: {testFscores[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Check the metrics returned by the cell above.\n",
        "    <ol>\n",
        "        <li>What do accuracy and F1-Score describe?</li>\n",
        "        <li>Do you think the model performs well given those results?</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us try once more by setting some parameters to address the overfitting issue. We will not worry to much about class imbalance since we have used stratified sampling to ensure same number of test locations per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## train another random forest with parameters to control overfitting\n",
        "properties = ['demAspect', 'demElevationNorm', 'demSlope', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa']\n",
        "randomForest = ee.Classifier.smileRandomForest(\n",
        "    numberOfTrees=50,             # sufficient ensemble size\n",
        "    maxNodes=32,                  # controls tree complexity (prevents deep memorization)\n",
        "    minLeafPopulation=5,          # ensures leaf nodes have enough samples (improves robustness)\n",
        "    bagFraction=0.63,             # recommended fraction for sampling\n",
        ").setOutputMode('CLASSIFICATION')\n",
        "classifier = randomForest.train(\n",
        "    features=training,\n",
        "    classProperty='flooded',\n",
        "    inputProperties=properties\n",
        ")\n",
        "\n",
        "# accuracy on training set\n",
        "trainConfusionMatrix = classifier.confusionMatrix()\n",
        "trainFscores = trainConfusionMatrix.fscore().getInfo()\n",
        "print(f\"train accuracy: {trainConfusionMatrix.accuracy().getInfo():.3f}\")\n",
        "print(f\"train f-score non-flooded: {trainFscores[0]:.3f}\")\n",
        "print(f\"train f-score flooded: {trainFscores[1]:.3f}\")\n",
        "\n",
        "# accuracy on validation set\n",
        "testConfusionMatrix = validation.classify(classifier).errorMatrix('flooded', 'classification')\n",
        "testFscores = testConfusionMatrix.fscore().getInfo()\n",
        "print(f\"validation accuracy: {testConfusionMatrix.accuracy().getInfo():.3f}\")\n",
        "print(f\"validation f-score non-flooded: {testFscores[0]:.3f}\")\n",
        "print(f\"validation f-score flooded: {testFscores[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Check the metrics returned by the new model.\n",
        "    <ol>\n",
        "        <li>Could we improve our model?</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Prediction\n",
        "\n",
        "We know that our model is flawed, but let's still go ahead and run some predictions.\n",
        "\n",
        "The cell below defined the *predict* function, which takes a region of interest and a classifier (our random forest) as input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #f38a21ff;\">\n",
        "  <strong style=\"color: #f38a21ff;\">Task:</strong> Try to understand the code in the cell below.\n",
        "    <ol>\n",
        "        <li>What does the <em>predict</em> function do exactly?</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"padding: 15px; border-left: 6px solid #1fbd5bff;\">\n",
        "<strong style=\"color: #1fbd5bff;\">Solution:</strong>\n",
        "  <ol>\n",
        "    <li>The <em>predict </em>function creates a composite image by combining all the datasets we used for model training. It normalizes the elevation and aggregates precipitation. It then classifies every pixel in the composite using the pre-trained model.</li>\n",
        "  </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrmCVjlIDQZp"
      },
      "outputs": [],
      "source": [
        "def predict(roi: ee.Geometry, classifier: ee.Classifier) -> ee.Image:\n",
        "  \"\"\"\n",
        "  Predict flood probability for a given region of interest.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  roi : ee.Geometry\n",
        "    Region of interest.\n",
        "  classifier : ee.Classifier\n",
        "    Trained classifier.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.Image\n",
        "    Flood probabilities.\n",
        "  \"\"\"\n",
        "\n",
        "  ## normalize elevation\n",
        "  elevationRange = dem.mosaic().reduceRegion(geometry=roi, reducer=ee.Reducer.minMax(), scale=30, bestEffort=True)\n",
        "  min = ee.Number(elevationRange.get('DEM_min'))\n",
        "  max = ee.Number(elevationRange.get('DEM_max'))\n",
        "\n",
        "  ## calculate start and end data for precipitation data aggregation\n",
        "  end = ee.Date('2024-10-31T00:00:00').millis()\n",
        "  start = end.subtract(1209600000) # timestamp in milliseconds: 60 * 60 * 24 * 14 * 1000\n",
        "\n",
        "  ## create composite of all relevant datasets\n",
        "  composite = ee.Image.cat(\n",
        "      ee.Terrain.aspect(dem.mosaic()),\n",
        "      dem.mosaic().unitScale(min, max),\n",
        "      ee.Terrain.slope(dem.mosaic()),\n",
        "      landcover.first(),\n",
        "      prec.filter(ee.Filter.date(start, end)).max(),\n",
        "      prec.filter(ee.Filter.date(start, end)).sum(),\n",
        "      runoffPotential,\n",
        "      hydro.select('upa')\n",
        "  ).rename(properties)\n",
        "\n",
        "  ## classify the composite\n",
        "  classifier = classifier.setOutputMode('MULTIPROBABILITY')\n",
        "  classified = composite.classify(classifier).clip(roi)\n",
        "  probabilities = classified.arrayFlatten([['non-flooded', 'flooded']])\n",
        "  probability = probabilities.select('flooded')\n",
        "\n",
        "  return probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are ready to make predictions. For this, we call our *predict* function for a given region of interest using our random forest.\n",
        "\n",
        "<div style=\"padding: 15px; border-left: 6px solid #e12525ff;\">\n",
        "  <strong style=\"color: #e12525ff;\">Warning:</strong> The cell below uses the map bounds of our map where we explored the data as the extent for which to compute predictions. Make sure to zoom to a relatively small area to avoid long running computations.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HgIVRX3f6J3"
      },
      "outputs": [],
      "source": [
        "## run prediction for current map bounds\n",
        "probability = predict(roi=ee.Geometry.BBox(*Map.getBounds()), classifier=classifier)\n",
        "\n",
        "## update mask to exclude permanent water\n",
        "permanentWater = globalFlood.select('jrc_perm_water').mosaic()\n",
        "probability = probability.updateMask(permanentWater.neq(1))\n",
        "\n",
        "## update the map\n",
        "probability_vis = {'min':0, 'max':1, 'palette':cm.palettes.cividis}\n",
        "Map.addLayer(probability.selfMask(), probability_vis, 'Flooded probability')\n",
        "Map.add_colorbar(probability_vis, label=\"Flooded probability\", layer_name=\"Flooded probability\", font_size=9)\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Feedback\n",
        "\n",
        "Providing a 2 minute feedback would help me to improve the exercise.\n",
        "Please run the cell below to display a Google Form where you can provide your feedback. I will not collect your mail address so the feedback is anonymous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxH4RUe4rW3I"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<iframe src=\"https://docs.google.com/forms/d/e/1FAIpQLScg8j6ORkqgWw4QEHpkeOy2PxYKSdgop3PPvaA1_WT54igFIA/viewform?embedded=true\" width=\"640\" height=\"1304\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loadingâ€¦</iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TebjhRrVgpVt"
      },
      "source": [
        "---\n",
        "## Bonus: run country-scale prediction\n",
        "The code below runs the trained model for all of Switzerland at 30 m resolution and exports the result to GEE. It runs in about 20 minutes. No need to run in the lab, but feel free to try it out and play around with different models, geographies and settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXdcJDjWgVrY"
      },
      "outputs": [],
      "source": [
        "## get country shape\n",
        "countries = ee.FeatureCollection('WM/geoLab/geoBoundaries/600/ADM0')\n",
        "ch = countries.filterMetadata('shapeName', 'equals', 'Switzerland')\n",
        "\n",
        "## run prediction for Switzerland\n",
        "flooded_prob = predict(roi=ch.geometry(), classifier=classifier)\n",
        "\n",
        "## update the map\n",
        "flooded_prob_vis = {'min':0, 'max':1, 'palette':cm.palettes.cividis}\n",
        "Map.addLayer(flooded_prob.selfMask(), flooded_prob_vis, 'Flooded probability')\n",
        "Map.add_colorbar(flooded_prob_vis, label=\"CH flooded probability\", layer_name=\"CH flooded probability\", font_size=9)\n",
        "Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rWlXxOGfqQM"
      },
      "outputs": [],
      "source": [
        "## create export task\n",
        "task = ee.batch.Export.image.toAsset(\n",
        "  flooded_prob,\n",
        "  description='flood475-ch-prediction',\n",
        "  assetId=f\"projects/{PROJECT_ID}/assets/flood475_ch_prediction\",\n",
        "  scale=30,\n",
        "  maxPixels=500_000_000\n",
        ")\n",
        "\n",
        "## run and monitor the task\n",
        "task.start()\n",
        "while task.active():\n",
        "  ts = task.status()\n",
        "  if ts['start_timestamp_ms']>0:\n",
        "    s = round((ts['update_timestamp_ms']-ts['start_timestamp_ms'])/1000)\n",
        "  else:\n",
        "    s = round((ts['update_timestamp_ms']-ts['creation_timestamp_ms'])/1000)\n",
        "  print(f\"task '{ts['description']}' is {ts['state']} for {s} seconds\")\n",
        "  time.sleep(60)\n",
        "task.status()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
