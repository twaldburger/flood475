{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geo475 - Flood prediction in Google Earth Engine\n",
        "Go through the notebook and run the cells. Try to understand the code and the overall approach.  \n",
        "Feel free to update code where you see room for improvement.  \n",
        "\n",
        "There are several tasks in the notebook. Please try to solve them but don't spend too much time on them. The goal is to understand the process and the code - solving all the tasks is secondary.  \n",
        "\n",
        "A notebook including some of countless solutions to the tasks can be found [here](https://github.com/twaldburger/flood475/blob/master/geo475_flood_prediction_in_gee_master.ipynb).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWQwO95HL-yd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Setup"
      ],
      "metadata": {
        "id": "zOtw_pQpNp1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import geemap\n",
        "import geemap.colormaps as cm\n",
        "import time\n",
        "\n",
        "## set some parameters, please update with your project id\n",
        "PROJECT_ID = '' # your GEE project id\n",
        "SAMPLE_SIZE = 100 # number of training locations per flood event and class\n",
        "SEED = 3414 # for reproducible results\n",
        "\n",
        "## connect to GEE\n",
        "try:\n",
        "    ee.Initialize()\n",
        "except ee.EEException:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project=PROJECT_ID)"
      ],
      "metadata": {
        "id": "munACIb96Vfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data exploration and visualization"
      ],
      "metadata": {
        "id": "gl1rsslKSJ7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## define the datasets from which to derive the input features\n",
        "globalFlood = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\")\n",
        "dem = ee.ImageCollection('COPERNICUS/DEM/GLO30') \\\n",
        "        .select('DEM')\n",
        "landcover = ee.ImageCollection('ESA/WorldCover/v200')\n",
        "hydro = ee.Image('MERIT/Hydro/v1_0_1')\n",
        "prec = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \\\n",
        "         .select('total_precipitation')\n",
        "runoffPotential = ee.Image('projects/sat-io/open-datasets/HiHydroSoilv2_0/Hydrologic_Soil_Group_250m') \\\n",
        "                    .remap([1, 2, 3, 4, 14, 24, 34], [1, 2, 3, 4, 1, 3, 4]) \\\n",
        "                    .select('remapped')"
      ],
      "metadata": {
        "id": "pBHxsikA6Vbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Get an overview on the datasets we use. What data do they provide? Who produced them? What is their spatial and temporal resolution? A good starting point is the [Earth Engine Data Catalog](https://developers.google.com/earth-engine/datasets)."
      ],
      "metadata": {
        "id": "xMhp6-quctsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## subtract the permanent water bodies from the flooded areas\n",
        "def subtractPermanentWater(img):\n",
        "  flood = img.select('flooded')\n",
        "  perm = img.select('jrc_perm_water')\n",
        "  return flood.multiply(perm.eq(0))\n",
        "flood = globalFlood.map(subtractPermanentWater).sum()\n",
        "\n",
        "## initialize map and add some basemaps\n",
        "# see https://stackoverflow.com/a/33023651 for Google basemap list\n",
        "Map = geemap.Map(center=[27, -81], zoom=7, basemap='CartoDB.DarkMatter')\n",
        "Map.add_basemap('CartoDB.Positron', show=False)\n",
        "Map.add_tile_layer(\"https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}\", name=\"Google.Roadmap\", attribution=\"Google\", shown=False)\n",
        "Map.add_tile_layer(\"https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}\", name=\"Google.Satellite\", attribution=\"Google\", shown=False)\n",
        "\n",
        "## add historic floods\n",
        "flood_vis = {'min':0, 'max':10, 'palette':cm.palettes.Blues}\n",
        "Map.add_layer(flood.selfMask(), flood_vis, 'Historic floods')\n",
        "Map.add_colorbar(flood_vis, label=\"Number of floods\", layer_name=\"Historic floods\")\n",
        "\n",
        "## display map\n",
        "Map"
      ],
      "metadata": {
        "id": "TmwnW78Of3Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Add the input datasets to the map so you can explore them visually. We are interested in elevation, landcover, upstream drainage area, precipitation and runoff potential. You can find the geemap documentation [here](https://geemap.org/)."
      ],
      "metadata": {
        "id": "BUj9DEb7fU4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Training dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "Yv7ybAUMSDmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pointQuery(fc:ee.FeatureCollection, img:ee.Image, prop:str) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Returns pixel values at locations using a feature collection and an image.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  fc: : ee.FeatureCollection\n",
        "    Collection of points at which to query the image.\n",
        "  img : ee.Image\n",
        "    The image to query.\n",
        "  prop : str\n",
        "    Name of new property to hold the query results.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Input FeatureCollection with lookup values added as new property.\n",
        "  \"\"\"\n",
        "  fc = img.reduceRegions(collection=fc, reducer=ee.Reducer.first())\n",
        "  return fc.map(lambda feat: feat.set(prop, feat.get('first')))\n",
        "\n",
        "\n",
        "def removeProperty(fc:ee.FeatureCollection, prop:str) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Removes a property by name from a feature collection.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  fc : ee.FeatureCollection\n",
        "    Collection from which to remove the property.\n",
        "  prop : str\n",
        "    Property to remove.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Input collection without the removed property.\n",
        "  \"\"\"\n",
        "  selectProperties = fc.propertyNames().filter(ee.Filter.neq('item', prop))\n",
        "  return fc.select(selectProperties)\n",
        "\n",
        "\n",
        "def createSample(img:ee.Image) -> ee.FeatureCollection:\n",
        "  \"\"\"\n",
        "  Samples training dataset for a single flood image.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  img : ee.Image\n",
        "    Input image.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.FeatureCollection\n",
        "    Sampled and enriched training data.\n",
        "  \"\"\"\n",
        "\n",
        "  ## subtract permanent water bodies from flooded areas\n",
        "  permanent = img.select('jrc_perm_water')\n",
        "  water = img.select('flooded')\n",
        "  flooded = water.subtract(permanent).gt(0)\n",
        "\n",
        "  ## get the total and maximum precipitation over 14 days prior to the event end date\n",
        "  end = img.getNumber('system:time_end')\n",
        "  start = end.subtract(1209600000) # timestamp in milliseconds: 60 * 60 * 24 * 14 * 1000\n",
        "  precSum = prec.filter(ee.Filter.date(start, end)).sum()\n",
        "  precMax = prec.filter(ee.Filter.date(start, end)).max()\n",
        "\n",
        "  ## sample equal number of flooded and non-flooded points\n",
        "  sample = flooded.stratifiedSample(numPoints=SAMPLE_SIZE, classBand='flooded', geometries=True)\n",
        "\n",
        "  ## add image id in case we want to join the event metadata later\n",
        "  sample = sample.map(lambda x: x.set('eventId', img.get('system:index')))\n",
        "\n",
        "  ## enrich sample by running point lookups on multiple datasets\n",
        "  sample = pointQuery(sample, dem.mosaic(), 'demElevationAbs')\n",
        "  sample = pointQuery(sample, ee.Terrain.aspect(dem.mosaic()), 'demAspect')\n",
        "  sample = pointQuery(sample, ee.Terrain.slope(dem.mosaic()), 'demSlope')\n",
        "  sample = pointQuery(sample, landcover.first(), 'landcover')\n",
        "  sample = pointQuery(sample, hydro.select('upa'), 'upa')\n",
        "  sample = pointQuery(sample, runoffPotential, 'runoffPot')\n",
        "  sample = pointQuery(sample, precSum, 'precSum')\n",
        "  sample = pointQuery(sample, precMax, 'precMax')\n",
        "\n",
        "  ## remove first-property\n",
        "  sample = sample.map(lambda feat: removeProperty(feat, 'first'))\n",
        "\n",
        "  ## normalize elevation\n",
        "  elevationRange = dem.mosaic().reduceRegion(geometry=img.geometry(), reducer=ee.Reducer.minMax())\n",
        "  min = ee.Number(elevationRange.get('DEM_min'))\n",
        "  max = ee.Number(elevationRange.get('DEM_max'))\n",
        "  def normalizeElevation(feat:ee.Feature) -> ee.Feature:\n",
        "    return feat.set('demElevationNorm', (ee.Number(feat.get('demElevationAbs')).subtract(min)).divide(max.subtract(min)))\n",
        "  sample = sample.filter(ee.Filter.notNull(ee.List(['demElevationAbs']))).map(normalizeElevation)\n",
        "\n",
        "  return sample"
      ],
      "metadata": {
        "id": "U7fUtqOy6VTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Try to understand the code in the cell above. Why are we using *ee.Image.stratifiedSample* in line 70 instead of using the much faster *ee.Image.Sample* method? Why are we using the complicated GEE methods in lines 65-76 and 90-94 instead of simply using plain Python? What does *ee.FeatureCollection.map* do? Why do we not just write a simple for-loop instead? Why do we normalize the elevation values?"
      ],
      "metadata": {
        "id": "qL-_naeIdr1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create task to enrich sample and store the result as an asset\n",
        "properties = ['demAspect', 'demElevationAbs', 'demElevationNorm', 'demSlope', 'eventId', 'flooded', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa', '.geo']\n",
        "sample = globalFlood.map(createSample).flatten()\n",
        "sample = sample.filter(ee.Filter.notNull(properties)).distinct(properties)\n",
        "task = ee.batch.Export.table.toAsset(sample, description='flood475-sampling', assetId=f\"projects/{PROJECT_ID}/assets/flood475_sample\")"
      ],
      "metadata": {
        "id": "W6ErNPvdBZm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## run and monitor the task\n",
        "task.start()\n",
        "while task.active():\n",
        "  ts = task.status()\n",
        "  if ts['start_timestamp_ms']>0:\n",
        "    s = round((ts['update_timestamp_ms']-ts['start_timestamp_ms'])/1000)\n",
        "  else:\n",
        "    s = round((ts['update_timestamp_ms']-ts['creation_timestamp_ms'])/1000)\n",
        "  print(f\"task '{ts['description']}' is {ts['state']} for {s} seconds\")\n",
        "  time.sleep(60)\n",
        "task.status()"
      ],
      "metadata": {
        "id": "s6I0aPqCXBIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** There are multiple places (outside of Google Colab) where we can also monitor our tasks. Can you find them?  \n",
        "\n",
        "> **Task:** Add the sampled data points to your map from above."
      ],
      "metadata": {
        "id": "jvoojztSaYDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Model training"
      ],
      "metadata": {
        "id": "PqUK7JJ68JfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## import the training dataset\n",
        "sample = ee.FeatureCollection(f\"projects/{PROJECT_ID}/assets/flood475_sample\")\n",
        "# sample = ee.FeatureCollection(f\"projects/ee-timwaldburger-flood475/assets/flood475_sample\")\n",
        "\n",
        "## partition into 70% training and 30% validation samples\n",
        "sample = sample.randomColumn('random', seed=SEED)\n",
        "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
        "validation = sample.filter(ee.Filter.gte('random', 0.7))\n",
        "\n",
        "## train a random forest\n",
        "properties = ['demAspect', 'demElevationNorm', 'demSlope', 'landcover', 'precMax', 'precSum', 'runoffPot', 'upa']\n",
        "randomForest = ee.Classifier.smileRandomForest(10).setOutputMode('CLASSIFICATION')\n",
        "classifier = randomForest.train(\n",
        "    features=training,\n",
        "    classProperty='flooded',\n",
        "    inputProperties=properties\n",
        ")"
      ],
      "metadata": {
        "id": "V6XMurxl8NJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on training set\n",
        "trainConfusionMatrix = classifier.confusionMatrix()\n",
        "trainFscores = trainConfusionMatrix.fscore().getInfo()\n",
        "print(f\"train accuracy: {trainConfusionMatrix.accuracy().getInfo()}\")\n",
        "print(f\"train f-score non-flooded: {trainFscores[0]}\")\n",
        "print(f\"train f-score flooded: {trainFscores[1]}\")\n",
        "\n",
        "# accuracy on test set\n",
        "testConfusionMatrix = validation.classify(classifier).errorMatrix('flooded', 'classification')\n",
        "testFscores = testConfusionMatrix.fscore().getInfo()\n",
        "print(f\"test accuracy: {testConfusionMatrix.accuracy().getInfo()}\")\n",
        "print(f\"test f-score non-flooded: {testFscores[0]}\")\n",
        "print(f\"test f-score flooded: {testFscores[1]}\")"
      ],
      "metadata": {
        "id": "UAbN6t2uMXlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** What do accuracy and F1-Score describe? Do you think your model performs well given those results?"
      ],
      "metadata": {
        "id": "5BtaK0kpgM8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Prediction"
      ],
      "metadata": {
        "id": "rZAwkZyHCt-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(roi: ee.Geometry, classifier: ee.Classifier) -> ee.Image:\n",
        "  \"\"\"\n",
        "  Predict flood probability for a given region of interest.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  roi : ee.Geometry\n",
        "    Region of interest.\n",
        "  classifier : ee.Classifier\n",
        "    Trained classifier.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ee.Image\n",
        "    Flood probabilities.\n",
        "  \"\"\"\n",
        "\n",
        "  ## normalize elevation\n",
        "  elevationRange = dem.mosaic().reduceRegion(geometry=roi, reducer=ee.Reducer.minMax(), scale=30, bestEffort=True)\n",
        "  min = ee.Number(elevationRange.get('DEM_min'))\n",
        "  max = ee.Number(elevationRange.get('DEM_max'))\n",
        "\n",
        "  ## calculate start and end data for precipitation data aggregation\n",
        "  end = ee.Date('2024-10-31T00:00:00').millis()\n",
        "  start = end.subtract(1209600000) # timestamp in milliseconds: 60 * 60 * 24 * 14 * 1000\n",
        "\n",
        "  ## create composite of all relevant datasets\n",
        "  composite = ee.Image.cat(\n",
        "      ee.Terrain.aspect(dem.mosaic()),\n",
        "      dem.mosaic().unitScale(min, max),\n",
        "      ee.Terrain.slope(dem.mosaic()),\n",
        "      landcover.first(),\n",
        "      prec.filter(ee.Filter.date(start, end)).max(),\n",
        "      prec.filter(ee.Filter.date(start, end)).sum(),\n",
        "      runoffPotential,\n",
        "      hydro.select('upa')\n",
        "  ).rename(properties)\n",
        "\n",
        "  ## classify the composite\n",
        "  classifier = classifier.setOutputMode('MULTIPROBABILITY')\n",
        "  classified = composite.classify(classifier).clip(roi)\n",
        "  probabilities = classified.arrayFlatten([['non-flooded', 'flooded']])\n",
        "  probability = probabilities.select('flooded')\n",
        "\n",
        "  return probability"
      ],
      "metadata": {
        "id": "yrmCVjlIDQZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Try to understand the code in the cell above. What does the *predict*-function do?"
      ],
      "metadata": {
        "id": "nh_alZwKjkiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## run prediction for current map bounds\n",
        "probability = predict(roi=ee.Geometry.BBox(*Map.getBounds()), classifier=classifier)\n",
        "\n",
        "## update mask to exclude permanent water\n",
        "permanentWater = globalFlood.select('jrc_perm_water').mosaic()\n",
        "probability = probability.updateMask(permanentWater.neq(1))\n",
        "\n",
        "## update the map\n",
        "probability_vis = {'min':0, 'max':1, 'palette':cm.palettes.cividis}\n",
        "Map.addLayer(probability.selfMask(), probability_vis, 'Flooded probability')\n",
        "Map.add_colorbar(probability_vis, label=\"Flooded probability\", layer_name=\"Flooded probability\", font_size=9)\n",
        "Map"
      ],
      "metadata": {
        "id": "4HgIVRX3f6J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Task:** Remove pixels representing permanent water bodies from the prediction.  \n",
        "\n",
        "> **Task:** Check various areas on the map. Where does the model seem to perform well. Where does it perform bad? Can you explain why it performs bad in certain areas? Do you see any bias towards a specific feature?\n",
        "\n",
        "> **Task:** Go back to the cell where we trained the model and play around with hyperparameters. Can you improve the model?  \n",
        "\n",
        "> **Task:** Check in the GEE documentation which other models are available and try to run them. What differences do you see? Which model works best?"
      ],
      "metadata": {
        "id": "qhGDziOU_m2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Feedback\n",
        "\n",
        "I try to constantly improve the exercise and would therefore much appreciate if you could take 2 minutes to provide me a short feedback. Thank you!\n",
        "\n",
        "Please run the cell below to display a Google Form where you can provide your feedback. I will not collect your mail address so the feedback is anonymous."
      ],
      "metadata": {
        "id": "Sb2D0kRqrZHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<iframe src=\"https://docs.google.com/forms/d/e/1FAIpQLScg8j6ORkqgWw4QEHpkeOy2PxYKSdgop3PPvaA1_WT54igFIA/viewform?embedded=true\" width=\"640\" height=\"1304\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading…</iframe>"
      ],
      "metadata": {
        "id": "WxH4RUe4rW3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Bonus: run country-scale prediction\n",
        "The code below runs the trained model for all of Switzerland at 30 m resolution and exports the result to GEE. It runs in about 20 minutes. No need to run in the lab, but feel free to try it out and play around with different models, geographies and settings."
      ],
      "metadata": {
        "id": "TebjhRrVgpVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## get country shape\n",
        "countries = ee.FeatureCollection('WM/geoLab/geoBoundaries/600/ADM0')\n",
        "ch = countries.filterMetadata('shapeName', 'equals', 'Switzerland')\n",
        "\n",
        "## run prediction for Switzerland\n",
        "flooded_prob = predict(roi=ch.geometry(), classifier=classifier)\n",
        "\n",
        "## update the map\n",
        "flooded_prob_vis = {'min':0, 'max':1, 'palette':cm.palettes.cividis}\n",
        "Map.addLayer(flooded_prob.selfMask(), flooded_prob_vis, 'Flooded probability')\n",
        "Map.add_colorbar(flooded_prob_vis, label=\"CH flooded probability\", layer_name=\"CH flooded probability\", font_size=9)\n",
        "Map"
      ],
      "metadata": {
        "id": "AXdcJDjWgVrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create export task\n",
        "task = ee.batch.Export.image.toAsset(\n",
        "  flooded_prob,\n",
        "  description='flood475-ch-prediction',\n",
        "  assetId=f\"projects/{PROJECT_ID}/assets/flood475_ch_prediction\",\n",
        "  scale=30,\n",
        "  maxPixels=500_000_000\n",
        ")\n",
        "\n",
        "## run and monitor the task\n",
        "task.start()\n",
        "while task.active():\n",
        "  ts = task.status()\n",
        "  if ts['start_timestamp_ms']>0:\n",
        "    s = round((ts['update_timestamp_ms']-ts['start_timestamp_ms'])/1000)\n",
        "  else:\n",
        "    s = round((ts['update_timestamp_ms']-ts['creation_timestamp_ms'])/1000)\n",
        "  print(f\"task '{ts['description']}' is {ts['state']} for {s} seconds\")\n",
        "  time.sleep(60)\n",
        "task.status()"
      ],
      "metadata": {
        "id": "6rWlXxOGfqQM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}